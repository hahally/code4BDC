{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_food = pd.read_csv('./test_A/初赛A榜测试集/preliminary_a_food.csv')\n",
    "test_sub = pd.read_csv('./test_A/初赛A榜测试集/preliminary_a_submit_sample.csv')\n",
    "train_food = pd.read_csv('./train/训练集/train_food.csv')\n",
    "train_answer = pd.read_csv('./train/训练集/train_answer.csv')\n",
    "\n",
    "disease_feature1 = pd.read_csv('./train/训练集/disease_feature1.csv')\n",
    "disease_feature2 = pd.read_csv('./train/训练集/disease_feature2.csv')\n",
    "disease_feature3 = pd.read_csv('./train/训练集/disease_feature3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 降维(feats, nfeats=64):\n",
    "#     pca = PCA(n_components=nfeats,random_state=2023)\n",
    "    tsvd = TruncatedSVD(n_components=nfeats,algorithm='randomized', n_iter=50, random_state=2023, tol=0.0)\n",
    "    new_feats = tsvd.fit_transform(feats)\n",
    "    \n",
    "    return new_feats\n",
    "nfeats = 50\n",
    "new_feat1 = 降维(disease_feature1.iloc[:,1:], nfeats=nfeats)\n",
    "new_feat2 = 降维(disease_feature2.iloc[:,1:], nfeats=nfeats)\n",
    "new_feat3 = 降维(disease_feature3.iloc[:,1:], nfeats=nfeats)\n",
    "\n",
    "feat1 = pd.DataFrame(new_feat1)\n",
    "feat1.columns = [f\"pca_1_{i}\" for i in range(nfeats)]\n",
    "feat1['disease_id'] = disease_feature1.disease_id\n",
    "\n",
    "feat2 = pd.DataFrame(new_feat2)\n",
    "feat2.columns = [f\"pca_2_{i}\" for i in range(nfeats)]\n",
    "feat2['disease_id'] = disease_feature2.disease_id\n",
    "\n",
    "feat3 = pd.DataFrame(new_feat3)\n",
    "feat3.columns = [f\"pca_3_{i}\" for i in range(nfeats)]\n",
    "feat3['disease_id'] = disease_feature3.disease_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del disease_feature1,disease_feature2,disease_feature3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_answer.merge(train_food, on='food_id', how='left').merge(feat1, on='disease_id', how='left').merge(feat2, on='disease_id', how='left').merge(feat3, on='disease_id', how='left')\n",
    "test = test_sub.merge(test_food, on='food_id', how='left').merge(feat1, on='disease_id', how='left').merge(feat2, on='disease_id', how='left').merge(feat3, on='disease_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "feat_col = train.columns.tolist()[3:]\n",
    "x_train = train[feat_col]\n",
    "y_train = train['related']\n",
    "x_test = test[feat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': ['logloss','auc'],\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 5, # 树的最大深度\n",
    "    'alpha': 0, # 关于权重的L1正则化项\n",
    "    'lambda': 0,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 0,\n",
    "    'eta': 0.03, # 学习率\n",
    "    'nthread': -1,\n",
    "    'seed': 2023,\n",
    "}\n",
    "\n",
    "params_lgb = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    # 'num_class': 2,\n",
    "    'metric': {'binary_logloss', 'auc'},\n",
    "    'num_leaves': 30,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth':5,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.4,\n",
    "    'lambda_l2': 0.5,\n",
    "    'min_gain_to_split': 0.2,\n",
    "    'verbose': -1,\n",
    "    'num_threads': -1,\n",
    "    'feature_fraction_seed':2023,\n",
    "    'bagging_seed':2023,\n",
    "    'seed':2023\n",
    "}\n",
    "\n",
    "params_ctb = {\n",
    "    'learning_rate': 0.01,\n",
    "    'loss_function': \"Logloss\",\n",
    "    'eval_metric': \"AUC\",\n",
    "    'depth': 8,\n",
    "    'random_seed':2023,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'logging_level': 'Verbose',\n",
    "    'use_best_model': True,\n",
    "    'one_hot_max_size': 5,   #类别数量多于此数将使用ordered target statistics编码方法,默认值为2。\n",
    "    'boosting_type':\"Ordered\", #Ordered 或者Plain,数据量较少时建议使用Ordered,训练更慢但能够缓解梯度估计偏差。\n",
    "    'max_ctr_complexity': 4, #特征组合的最大特征数量，设置为1取消特征组合，设置为2只做两个特征的组合,默认为4。\n",
    "    'nan_mode': 'Min' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\hahally\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\envs\\hahally\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.919702\ttraining's binary_logloss: 0.219252\tvalid_1's auc: 0.909082\tvalid_1's binary_logloss: 0.225392\n",
      "[400]\ttraining's auc: 0.940321\ttraining's binary_logloss: 0.187647\tvalid_1's auc: 0.929966\tvalid_1's binary_logloss: 0.19586\n",
      "[600]\ttraining's auc: 0.948802\ttraining's binary_logloss: 0.172947\tvalid_1's auc: 0.937834\tvalid_1's binary_logloss: 0.182647\n",
      "[800]\ttraining's auc: 0.954543\ttraining's binary_logloss: 0.163403\tvalid_1's auc: 0.942835\tvalid_1's binary_logloss: 0.174404\n",
      "[1000]\ttraining's auc: 0.959029\ttraining's binary_logloss: 0.155504\tvalid_1's auc: 0.946847\tvalid_1's binary_logloss: 0.167637\n",
      "[1200]\ttraining's auc: 0.962622\ttraining's binary_logloss: 0.149034\tvalid_1's auc: 0.949679\tvalid_1's binary_logloss: 0.162396\n",
      "[1400]\ttraining's auc: 0.965349\ttraining's binary_logloss: 0.143989\tvalid_1's auc: 0.951823\tvalid_1's binary_logloss: 0.158464\n",
      "[1600]\ttraining's auc: 0.967636\ttraining's binary_logloss: 0.139445\tvalid_1's auc: 0.953606\tvalid_1's binary_logloss: 0.15506\n",
      "[1800]\ttraining's auc: 0.969744\ttraining's binary_logloss: 0.13527\tvalid_1's auc: 0.955019\tvalid_1's binary_logloss: 0.152135\n",
      "[2000]\ttraining's auc: 0.971657\ttraining's binary_logloss: 0.131604\tvalid_1's auc: 0.956419\tvalid_1's binary_logloss: 0.149615\n",
      "[2200]\ttraining's auc: 0.973421\ttraining's binary_logloss: 0.128026\tvalid_1's auc: 0.957703\tvalid_1's binary_logloss: 0.14722\n",
      "[2400]\ttraining's auc: 0.97495\ttraining's binary_logloss: 0.124712\tvalid_1's auc: 0.95861\tvalid_1's binary_logloss: 0.145239\n",
      "[2600]\ttraining's auc: 0.97646\ttraining's binary_logloss: 0.121639\tvalid_1's auc: 0.959542\tvalid_1's binary_logloss: 0.143447\n",
      "[2800]\ttraining's auc: 0.977809\ttraining's binary_logloss: 0.11882\tvalid_1's auc: 0.960291\tvalid_1's binary_logloss: 0.14189\n",
      "[3000]\ttraining's auc: 0.979127\ttraining's binary_logloss: 0.115941\tvalid_1's auc: 0.961135\tvalid_1's binary_logloss: 0.140233\n",
      "[3200]\ttraining's auc: 0.980463\ttraining's binary_logloss: 0.112946\tvalid_1's auc: 0.961951\tvalid_1's binary_logloss: 0.138611\n",
      "[3400]\ttraining's auc: 0.981603\ttraining's binary_logloss: 0.110323\tvalid_1's auc: 0.962674\tvalid_1's binary_logloss: 0.137149\n",
      "[3600]\ttraining's auc: 0.982643\ttraining's binary_logloss: 0.107931\tvalid_1's auc: 0.963312\tvalid_1's binary_logloss: 0.135931\n",
      "[3800]\ttraining's auc: 0.983543\ttraining's binary_logloss: 0.105754\tvalid_1's auc: 0.963763\tvalid_1's binary_logloss: 0.134951\n",
      "[4000]\ttraining's auc: 0.984456\ttraining's binary_logloss: 0.103514\tvalid_1's auc: 0.964197\tvalid_1's binary_logloss: 0.133934\n",
      "[4200]\ttraining's auc: 0.985364\ttraining's binary_logloss: 0.1012\tvalid_1's auc: 0.964671\tvalid_1's binary_logloss: 0.132878\n",
      "[4400]\ttraining's auc: 0.986174\ttraining's binary_logloss: 0.0990926\tvalid_1's auc: 0.965093\tvalid_1's binary_logloss: 0.131935\n",
      "[4600]\ttraining's auc: 0.986944\ttraining's binary_logloss: 0.097062\tvalid_1's auc: 0.965445\tvalid_1's binary_logloss: 0.131118\n",
      "[4800]\ttraining's auc: 0.987659\ttraining's binary_logloss: 0.0950616\tvalid_1's auc: 0.965826\tvalid_1's binary_logloss: 0.130261\n",
      "[5000]\ttraining's auc: 0.988415\ttraining's binary_logloss: 0.0930352\tvalid_1's auc: 0.966212\tvalid_1's binary_logloss: 0.129431\n",
      "[5200]\ttraining's auc: 0.989099\ttraining's binary_logloss: 0.0911483\tvalid_1's auc: 0.966621\tvalid_1's binary_logloss: 0.128565\n",
      "[5400]\ttraining's auc: 0.989713\ttraining's binary_logloss: 0.0893604\tvalid_1's auc: 0.966903\tvalid_1's binary_logloss: 0.127872\n",
      "[5600]\ttraining's auc: 0.990316\ttraining's binary_logloss: 0.0875455\tvalid_1's auc: 0.967236\tvalid_1's binary_logloss: 0.127151\n",
      "[5800]\ttraining's auc: 0.990874\ttraining's binary_logloss: 0.0858765\tvalid_1's auc: 0.967508\tvalid_1's binary_logloss: 0.12652\n",
      "[6000]\ttraining's auc: 0.991376\ttraining's binary_logloss: 0.0842655\tvalid_1's auc: 0.967691\tvalid_1's binary_logloss: 0.126018\n",
      "[6200]\ttraining's auc: 0.991858\ttraining's binary_logloss: 0.0826869\tvalid_1's auc: 0.967904\tvalid_1's binary_logloss: 0.125497\n",
      "[6400]\ttraining's auc: 0.992352\ttraining's binary_logloss: 0.0811001\tvalid_1's auc: 0.968174\tvalid_1's binary_logloss: 0.124963\n",
      "[6600]\ttraining's auc: 0.992798\ttraining's binary_logloss: 0.0796073\tvalid_1's auc: 0.968366\tvalid_1's binary_logloss: 0.12451\n",
      "[6800]\ttraining's auc: 0.993222\ttraining's binary_logloss: 0.0781341\tvalid_1's auc: 0.968497\tvalid_1's binary_logloss: 0.124136\n",
      "[7000]\ttraining's auc: 0.993576\ttraining's binary_logloss: 0.0767923\tvalid_1's auc: 0.968655\tvalid_1's binary_logloss: 0.123705\n",
      "[7200]\ttraining's auc: 0.993969\ttraining's binary_logloss: 0.0753748\tvalid_1's auc: 0.968835\tvalid_1's binary_logloss: 0.123287\n",
      "[7400]\ttraining's auc: 0.994298\ttraining's binary_logloss: 0.0740621\tvalid_1's auc: 0.968991\tvalid_1's binary_logloss: 0.122886\n",
      "[7600]\ttraining's auc: 0.994655\ttraining's binary_logloss: 0.0726002\tvalid_1's auc: 0.969204\tvalid_1's binary_logloss: 0.122336\n",
      "[7800]\ttraining's auc: 0.994948\ttraining's binary_logloss: 0.0713631\tvalid_1's auc: 0.969303\tvalid_1's binary_logloss: 0.122042\n",
      "[8000]\ttraining's auc: 0.995248\ttraining's binary_logloss: 0.0701088\tvalid_1's auc: 0.969423\tvalid_1's binary_logloss: 0.121681\n",
      "[8200]\ttraining's auc: 0.995547\ttraining's binary_logloss: 0.0687716\tvalid_1's auc: 0.969591\tvalid_1's binary_logloss: 0.12127\n",
      "[8400]\ttraining's auc: 0.995831\ttraining's binary_logloss: 0.067542\tvalid_1's auc: 0.969721\tvalid_1's binary_logloss: 0.120948\n",
      "[8600]\ttraining's auc: 0.996081\ttraining's binary_logloss: 0.0663576\tvalid_1's auc: 0.969844\tvalid_1's binary_logloss: 0.120637\n",
      "[8800]\ttraining's auc: 0.996331\ttraining's binary_logloss: 0.0651573\tvalid_1's auc: 0.969997\tvalid_1's binary_logloss: 0.120235\n",
      "[9000]\ttraining's auc: 0.996553\ttraining's binary_logloss: 0.064048\tvalid_1's auc: 0.970078\tvalid_1's binary_logloss: 0.119993\n",
      "[9200]\ttraining's auc: 0.996785\ttraining's binary_logloss: 0.0628588\tvalid_1's auc: 0.970235\tvalid_1's binary_logloss: 0.119599\n",
      "[9400]\ttraining's auc: 0.996971\ttraining's binary_logloss: 0.061833\tvalid_1's auc: 0.970365\tvalid_1's binary_logloss: 0.119318\n",
      "[9600]\ttraining's auc: 0.997145\ttraining's binary_logloss: 0.0608126\tvalid_1's auc: 0.970434\tvalid_1's binary_logloss: 0.119135\n",
      "[9800]\ttraining's auc: 0.997316\ttraining's binary_logloss: 0.0598484\tvalid_1's auc: 0.970493\tvalid_1's binary_logloss: 0.119011\n",
      "[10000]\ttraining's auc: 0.997474\ttraining's binary_logloss: 0.0589061\tvalid_1's auc: 0.970584\tvalid_1's binary_logloss: 0.118742\n",
      "[10200]\ttraining's auc: 0.997622\ttraining's binary_logloss: 0.0580314\tvalid_1's auc: 0.970624\tvalid_1's binary_logloss: 0.118604\n",
      "[10400]\ttraining's auc: 0.997768\ttraining's binary_logloss: 0.0571042\tvalid_1's auc: 0.970714\tvalid_1's binary_logloss: 0.118392\n",
      "[10600]\ttraining's auc: 0.997908\ttraining's binary_logloss: 0.0561643\tvalid_1's auc: 0.970776\tvalid_1's binary_logloss: 0.118181\n",
      "[10800]\ttraining's auc: 0.998037\ttraining's binary_logloss: 0.0553222\tvalid_1's auc: 0.970805\tvalid_1's binary_logloss: 0.118115\n",
      "[11000]\ttraining's auc: 0.998153\ttraining's binary_logloss: 0.0545237\tvalid_1's auc: 0.970805\tvalid_1's binary_logloss: 0.118083\n",
      "[11200]\ttraining's auc: 0.998265\ttraining's binary_logloss: 0.0537114\tvalid_1's auc: 0.970836\tvalid_1's binary_logloss: 0.117965\n",
      "[11400]\ttraining's auc: 0.998374\ttraining's binary_logloss: 0.0528591\tvalid_1's auc: 0.970915\tvalid_1's binary_logloss: 0.117756\n",
      "[11600]\ttraining's auc: 0.998478\ttraining's binary_logloss: 0.0520609\tvalid_1's auc: 0.970958\tvalid_1's binary_logloss: 0.117649\n",
      "[11800]\ttraining's auc: 0.998576\ttraining's binary_logloss: 0.0512278\tvalid_1's auc: 0.971028\tvalid_1's binary_logloss: 0.11744\n",
      "[12000]\ttraining's auc: 0.998667\ttraining's binary_logloss: 0.0504398\tvalid_1's auc: 0.971104\tvalid_1's binary_logloss: 0.117248\n",
      "[12200]\ttraining's auc: 0.998747\ttraining's binary_logloss: 0.0496945\tvalid_1's auc: 0.971161\tvalid_1's binary_logloss: 0.117095\n",
      "[12400]\ttraining's auc: 0.998828\ttraining's binary_logloss: 0.0489471\tvalid_1's auc: 0.971235\tvalid_1's binary_logloss: 0.116974\n",
      "[12600]\ttraining's auc: 0.998899\ttraining's binary_logloss: 0.0481996\tvalid_1's auc: 0.971271\tvalid_1's binary_logloss: 0.116844\n",
      "[12800]\ttraining's auc: 0.998963\ttraining's binary_logloss: 0.0475651\tvalid_1's auc: 0.971292\tvalid_1's binary_logloss: 0.116794\n",
      "[13000]\ttraining's auc: 0.999027\ttraining's binary_logloss: 0.0468929\tvalid_1's auc: 0.971328\tvalid_1's binary_logloss: 0.116696\n",
      "[13200]\ttraining's auc: 0.999097\ttraining's binary_logloss: 0.0461819\tvalid_1's auc: 0.971365\tvalid_1's binary_logloss: 0.116629\n",
      "[13400]\ttraining's auc: 0.999154\ttraining's binary_logloss: 0.0455195\tvalid_1's auc: 0.971387\tvalid_1's binary_logloss: 0.11657\n",
      "[13600]\ttraining's auc: 0.999208\ttraining's binary_logloss: 0.0448774\tvalid_1's auc: 0.971403\tvalid_1's binary_logloss: 0.116508\n",
      "[13800]\ttraining's auc: 0.999255\ttraining's binary_logloss: 0.0442531\tvalid_1's auc: 0.97142\tvalid_1's binary_logloss: 0.116454\n",
      "[14000]\ttraining's auc: 0.999299\ttraining's binary_logloss: 0.0436336\tvalid_1's auc: 0.971455\tvalid_1's binary_logloss: 0.116345\n",
      "[14200]\ttraining's auc: 0.999342\ttraining's binary_logloss: 0.0430623\tvalid_1's auc: 0.9715\tvalid_1's binary_logloss: 0.116276\n",
      "[14400]\ttraining's auc: 0.99938\ttraining's binary_logloss: 0.0425246\tvalid_1's auc: 0.971501\tvalid_1's binary_logloss: 0.116246\n",
      "[14600]\ttraining's auc: 0.99942\ttraining's binary_logloss: 0.0419693\tvalid_1's auc: 0.971518\tvalid_1's binary_logloss: 0.1162\n",
      "[14800]\ttraining's auc: 0.999456\ttraining's binary_logloss: 0.0413934\tvalid_1's auc: 0.97155\tvalid_1's binary_logloss: 0.116119\n",
      "[15000]\ttraining's auc: 0.999489\ttraining's binary_logloss: 0.0408364\tvalid_1's auc: 0.971533\tvalid_1's binary_logloss: 0.116139\n",
      "[15200]\ttraining's auc: 0.999517\ttraining's binary_logloss: 0.0403341\tvalid_1's auc: 0.971561\tvalid_1's binary_logloss: 0.11609\n",
      "[15400]\ttraining's auc: 0.999544\ttraining's binary_logloss: 0.0398205\tvalid_1's auc: 0.971579\tvalid_1's binary_logloss: 0.11604\n",
      "[15600]\ttraining's auc: 0.999571\ttraining's binary_logloss: 0.0393023\tvalid_1's auc: 0.971603\tvalid_1's binary_logloss: 0.115977\n",
      "[15800]\ttraining's auc: 0.999597\ttraining's binary_logloss: 0.0388261\tvalid_1's auc: 0.971628\tvalid_1's binary_logloss: 0.11595\n",
      "[16000]\ttraining's auc: 0.999621\ttraining's binary_logloss: 0.0383447\tvalid_1's auc: 0.971637\tvalid_1's binary_logloss: 0.115942\n",
      "[16200]\ttraining's auc: 0.999643\ttraining's binary_logloss: 0.0378789\tvalid_1's auc: 0.971628\tvalid_1's binary_logloss: 0.115969\n",
      "[16400]\ttraining's auc: 0.999667\ttraining's binary_logloss: 0.0374011\tvalid_1's auc: 0.97164\tvalid_1's binary_logloss: 0.115979\n",
      "Early stopping, best iteration is:\n",
      "[15980]\ttraining's auc: 0.999618\ttraining's binary_logloss: 0.0383939\tvalid_1's auc: 0.971646\tvalid_1's binary_logloss: 0.115924\n",
      "0:\ttest: 0.7116938\tbest: 0.7116938 (0)\ttotal: 1.26s\tremaining: 1d 11h 8m 27s\n",
      "100:\ttest: 0.8612256\tbest: 0.8612256 (100)\ttotal: 1m 56s\tremaining: 1d 8h 6m 17s\n",
      "200:\ttest: 0.8787166\tbest: 0.8787166 (200)\ttotal: 3m 53s\tremaining: 1d 8h 12m 13s\n",
      "300:\ttest: 0.8962236\tbest: 0.8962236 (300)\ttotal: 5m 50s\tremaining: 1d 8h 14m 44s\n",
      "400:\ttest: 0.9087212\tbest: 0.9087212 (400)\ttotal: 7m 49s\tremaining: 1d 8h 23m 25s\n",
      "500:\ttest: 0.9183743\tbest: 0.9183743 (500)\ttotal: 9m 46s\tremaining: 1d 8h 22m 39s\n",
      "600:\ttest: 0.9258879\tbest: 0.9258879 (600)\ttotal: 11m 44s\tremaining: 1d 8h 20m 45s\n",
      "700:\ttest: 0.9310873\tbest: 0.9310873 (700)\ttotal: 13m 42s\tremaining: 1d 8h 22m 55s\n",
      "800:\ttest: 0.9355542\tbest: 0.9355542 (800)\ttotal: 15m 39s\tremaining: 1d 8h 19m 5s\n",
      "900:\ttest: 0.9392140\tbest: 0.9392140 (900)\ttotal: 17m 38s\tremaining: 1d 8h 21m 14s\n",
      "1000:\ttest: 0.9425816\tbest: 0.9425816 (1000)\ttotal: 19m 38s\tremaining: 1d 8h 23m 15s\n",
      "1100:\ttest: 0.9448222\tbest: 0.9448222 (1100)\ttotal: 21m 38s\tremaining: 1d 8h 24m 20s\n",
      "1200:\ttest: 0.9470971\tbest: 0.9470971 (1200)\ttotal: 23m 37s\tremaining: 1d 8h 24m 2s\n",
      "1300:\ttest: 0.9486897\tbest: 0.9486897 (1300)\ttotal: 25m 38s\tremaining: 1d 8h 25m 1s\n",
      "1400:\ttest: 0.9503208\tbest: 0.9503208 (1400)\ttotal: 27m 38s\tremaining: 1d 8h 25m 7s\n",
      "1500:\ttest: 0.9515583\tbest: 0.9515583 (1500)\ttotal: 29m 36s\tremaining: 1d 8h 22m 50s\n",
      "1600:\ttest: 0.9525379\tbest: 0.9525379 (1600)\ttotal: 31m 36s\tremaining: 1d 8h 22m 49s\n",
      "1700:\ttest: 0.9533250\tbest: 0.9533250 (1700)\ttotal: 33m 34s\tremaining: 1d 8h 20m 13s\n",
      "1800:\ttest: 0.9541921\tbest: 0.9541925 (1798)\ttotal: 35m 31s\tremaining: 1d 8h 17m 17s\n",
      "1900:\ttest: 0.9546428\tbest: 0.9546428 (1900)\ttotal: 37m 28s\tremaining: 1d 8h 14m 16s\n",
      "2000:\ttest: 0.9549988\tbest: 0.9549996 (1998)\ttotal: 39m 16s\tremaining: 1d 8h 3m 8s\n",
      "2100:\ttest: 0.9553840\tbest: 0.9553840 (2100)\ttotal: 41m 4s\tremaining: 1d 7h 53m 43s\n",
      "2200:\ttest: 0.9559366\tbest: 0.9559382 (2198)\ttotal: 42m 51s\tremaining: 1d 7h 44m 24s\n",
      "2300:\ttest: 0.9563347\tbest: 0.9563376 (2297)\ttotal: 44m 39s\tremaining: 1d 7h 35m 54s\n",
      "2400:\ttest: 0.9565590\tbest: 0.9565646 (2392)\ttotal: 46m 27s\tremaining: 1d 7h 28m 21s\n",
      "2500:\ttest: 0.9568624\tbest: 0.9568624 (2500)\ttotal: 48m 14s\tremaining: 1d 7h 20m 58s\n",
      "2600:\ttest: 0.9572327\tbest: 0.9572327 (2600)\ttotal: 50m 1s\tremaining: 1d 7h 13m 27s\n",
      "2700:\ttest: 0.9575567\tbest: 0.9575581 (2699)\ttotal: 51m 49s\tremaining: 1d 7h 6m 57s\n",
      "2800:\ttest: 0.9578687\tbest: 0.9578707 (2796)\ttotal: 53m 37s\tremaining: 1d 7h 1m 6s\n",
      "2900:\ttest: 0.9579507\tbest: 0.9579519 (2898)\ttotal: 55m 32s\tremaining: 1d 6h 58m 54s\n",
      "3000:\ttest: 0.9580047\tbest: 0.9580064 (2976)\ttotal: 57m 27s\tremaining: 1d 6h 57m 25s\n",
      "3100:\ttest: 0.9580198\tbest: 0.9580210 (3093)\ttotal: 59m 23s\tremaining: 1d 6h 55m 55s\n",
      "3200:\ttest: 0.9581818\tbest: 0.9581824 (3199)\ttotal: 1h 1m 19s\tremaining: 1d 6h 54m 37s\n",
      "3300:\ttest: 0.9583153\tbest: 0.9583153 (3300)\ttotal: 1h 3m 15s\tremaining: 1d 6h 53m 10s\n",
      "3400:\ttest: 0.9584366\tbest: 0.9584366 (3400)\ttotal: 1h 5m 10s\tremaining: 1d 6h 51m 12s\n",
      "3500:\ttest: 0.9584640\tbest: 0.9584695 (3474)\ttotal: 1h 7m 5s\tremaining: 1d 6h 49m 16s\n",
      "3600:\ttest: 0.9585394\tbest: 0.9585394 (3600)\ttotal: 1h 9m\tremaining: 1d 6h 47m 21s\n",
      "3700:\ttest: 0.9586447\tbest: 0.9586452 (3699)\ttotal: 1h 10m 55s\tremaining: 1d 6h 45m 28s\n",
      "3800:\ttest: 0.9587366\tbest: 0.9587367 (3798)\ttotal: 1h 12m 51s\tremaining: 1d 6h 43m 46s\n",
      "3900:\ttest: 0.9587927\tbest: 0.9587933 (3895)\ttotal: 1h 14m 46s\tremaining: 1d 6h 41m 51s\n",
      "4000:\ttest: 0.9588153\tbest: 0.9588168 (3996)\ttotal: 1h 16m 41s\tremaining: 1d 6h 39m 57s\n",
      "4100:\ttest: 0.9588559\tbest: 0.9588566 (4097)\ttotal: 1h 18m 34s\tremaining: 1d 6h 37m 26s\n",
      "4200:\ttest: 0.9588655\tbest: 0.9588720 (4185)\ttotal: 1h 20m 21s\tremaining: 1d 6h 32m 39s\n",
      "4300:\ttest: 0.9588649\tbest: 0.9588739 (4232)\ttotal: 1h 22m 8s\tremaining: 1d 6h 27m 35s\n",
      "4400:\ttest: 0.9589393\tbest: 0.9589395 (4398)\ttotal: 1h 23m 58s\tremaining: 1d 6h 24m 1s\n",
      "4500:\ttest: 0.9590544\tbest: 0.9590544 (4500)\ttotal: 1h 25m 53s\tremaining: 1d 6h 22m 13s\n",
      "4600:\ttest: 0.9590784\tbest: 0.9590904 (4533)\ttotal: 1h 27m 46s\tremaining: 1d 6h 19m 49s\n",
      "4700:\ttest: 0.9591416\tbest: 0.9591416 (4693)\ttotal: 1h 29m 34s\tremaining: 1d 6h 16m\n",
      "4800:\ttest: 0.9591605\tbest: 0.9591610 (4797)\ttotal: 1h 31m 23s\tremaining: 1d 6h 12m 17s\n",
      "4900:\ttest: 0.9591573\tbest: 0.9591637 (4848)\ttotal: 1h 33m 6s\tremaining: 1d 6h 6m 33s\n",
      "5000:\ttest: 0.9592077\tbest: 0.9592077 (5000)\ttotal: 1h 34m 49s\tremaining: 1d 6h 1m 23s\n",
      "5100:\ttest: 0.9593425\tbest: 0.9593425 (5100)\ttotal: 1h 36m 34s\tremaining: 1d 5h 56m 37s\n",
      "5200:\ttest: 0.9594285\tbest: 0.9594286 (5198)\ttotal: 1h 38m 20s\tremaining: 1d 5h 52m 22s\n",
      "5300:\ttest: 0.9595235\tbest: 0.9595249 (5292)\ttotal: 1h 40m 3s\tremaining: 1d 5h 47m 30s\n",
      "5400:\ttest: 0.9595507\tbest: 0.9595577 (5371)\ttotal: 1h 41m 45s\tremaining: 1d 5h 42m 18s\n",
      "5500:\ttest: 0.9595584\tbest: 0.9595606 (5469)\ttotal: 1h 43m 28s\tremaining: 1d 5h 37m 34s\n",
      "5600:\ttest: 0.9595588\tbest: 0.9595641 (5538)\ttotal: 1h 45m 13s\tremaining: 1d 5h 33m 30s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9595640697\n",
      "bestIteration = 5538\n",
      "\n",
      "Shrink model to first 5539 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\hahally\\lib\\site-packages\\xgboost\\core.py:571: FutureWarning: Pass `evals` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  format(\", \".join(args_msg)), FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:07:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.67261\ttrain-auc:0.71013\tvalid-logloss:0.67267\tvalid-auc:0.70552\n",
      "[100]\ttrain-logloss:0.22463\ttrain-auc:0.91689\tvalid-logloss:0.23107\tvalid-auc:0.90633\n",
      "[200]\ttrain-logloss:0.18160\ttrain-auc:0.94388\tvalid-logloss:0.19120\tvalid-auc:0.93263\n",
      "[300]\ttrain-logloss:0.16421\ttrain-auc:0.95384\tvalid-logloss:0.17559\tvalid-auc:0.94191\n",
      "[400]\ttrain-logloss:0.15363\ttrain-auc:0.95971\tvalid-logloss:0.16665\tvalid-auc:0.94695\n",
      "[500]\ttrain-logloss:0.14517\ttrain-auc:0.96411\tvalid-logloss:0.15977\tvalid-auc:0.95083\n",
      "[600]\ttrain-logloss:0.13872\ttrain-auc:0.96737\tvalid-logloss:0.15481\tvalid-auc:0.95351\n",
      "[700]\ttrain-logloss:0.13305\ttrain-auc:0.97021\tvalid-logloss:0.15095\tvalid-auc:0.95542\n",
      "[800]\ttrain-logloss:0.12845\ttrain-auc:0.97244\tvalid-logloss:0.14807\tvalid-auc:0.95685\n",
      "[900]\ttrain-logloss:0.12412\ttrain-auc:0.97464\tvalid-logloss:0.14548\tvalid-auc:0.95814\n",
      "[1000]\ttrain-logloss:0.12004\ttrain-auc:0.97651\tvalid-logloss:0.14304\tvalid-auc:0.95931\n",
      "[1100]\ttrain-logloss:0.11648\ttrain-auc:0.97813\tvalid-logloss:0.14104\tvalid-auc:0.96037\n",
      "[1200]\ttrain-logloss:0.11308\ttrain-auc:0.97970\tvalid-logloss:0.13914\tvalid-auc:0.96141\n",
      "[1300]\ttrain-logloss:0.10988\ttrain-auc:0.98116\tvalid-logloss:0.13774\tvalid-auc:0.96212\n",
      "[1400]\ttrain-logloss:0.10668\ttrain-auc:0.98254\tvalid-logloss:0.13628\tvalid-auc:0.96282\n",
      "[1500]\ttrain-logloss:0.10358\ttrain-auc:0.98384\tvalid-logloss:0.13488\tvalid-auc:0.96352\n",
      "[1600]\ttrain-logloss:0.10088\ttrain-auc:0.98492\tvalid-logloss:0.13377\tvalid-auc:0.96399\n",
      "[1700]\ttrain-logloss:0.09822\ttrain-auc:0.98601\tvalid-logloss:0.13267\tvalid-auc:0.96456\n",
      "[1800]\ttrain-logloss:0.09566\ttrain-auc:0.98699\tvalid-logloss:0.13158\tvalid-auc:0.96505\n",
      "[1900]\ttrain-logloss:0.09330\ttrain-auc:0.98786\tvalid-logloss:0.13072\tvalid-auc:0.96546\n",
      "[2000]\ttrain-logloss:0.09086\ttrain-auc:0.98874\tvalid-logloss:0.12981\tvalid-auc:0.96587\n",
      "[2100]\ttrain-logloss:0.08876\ttrain-auc:0.98947\tvalid-logloss:0.12908\tvalid-auc:0.96619\n",
      "[2200]\ttrain-logloss:0.08668\ttrain-auc:0.99016\tvalid-logloss:0.12843\tvalid-auc:0.96649\n",
      "[2300]\ttrain-logloss:0.08467\ttrain-auc:0.99087\tvalid-logloss:0.12783\tvalid-auc:0.96673\n",
      "[2400]\ttrain-logloss:0.08262\ttrain-auc:0.99152\tvalid-logloss:0.12723\tvalid-auc:0.96699\n",
      "[2500]\ttrain-logloss:0.08081\ttrain-auc:0.99207\tvalid-logloss:0.12668\tvalid-auc:0.96727\n",
      "[2600]\ttrain-logloss:0.07881\ttrain-auc:0.99266\tvalid-logloss:0.12614\tvalid-auc:0.96746\n",
      "[2700]\ttrain-logloss:0.07707\ttrain-auc:0.99316\tvalid-logloss:0.12578\tvalid-auc:0.96759\n",
      "[2800]\ttrain-logloss:0.07529\ttrain-auc:0.99364\tvalid-logloss:0.12534\tvalid-auc:0.96776\n",
      "[2900]\ttrain-logloss:0.07373\ttrain-auc:0.99405\tvalid-logloss:0.12493\tvalid-auc:0.96792\n",
      "[3000]\ttrain-logloss:0.07210\ttrain-auc:0.99447\tvalid-logloss:0.12443\tvalid-auc:0.96813\n",
      "[3100]\ttrain-logloss:0.07054\ttrain-auc:0.99488\tvalid-logloss:0.12400\tvalid-auc:0.96830\n",
      "[3200]\ttrain-logloss:0.06907\ttrain-auc:0.99523\tvalid-logloss:0.12375\tvalid-auc:0.96840\n",
      "[3300]\ttrain-logloss:0.06764\ttrain-auc:0.99557\tvalid-logloss:0.12353\tvalid-auc:0.96849\n",
      "[3400]\ttrain-logloss:0.06623\ttrain-auc:0.99588\tvalid-logloss:0.12330\tvalid-auc:0.96858\n",
      "[3500]\ttrain-logloss:0.06487\ttrain-auc:0.99617\tvalid-logloss:0.12301\tvalid-auc:0.96869\n",
      "[3600]\ttrain-logloss:0.06359\ttrain-auc:0.99644\tvalid-logloss:0.12276\tvalid-auc:0.96880\n",
      "[3700]\ttrain-logloss:0.06230\ttrain-auc:0.99668\tvalid-logloss:0.12256\tvalid-auc:0.96886\n",
      "[3800]\ttrain-logloss:0.06106\ttrain-auc:0.99691\tvalid-logloss:0.12249\tvalid-auc:0.96885\n",
      "[3900]\ttrain-logloss:0.05980\ttrain-auc:0.99714\tvalid-logloss:0.12229\tvalid-auc:0.96894\n",
      "[4000]\ttrain-logloss:0.05861\ttrain-auc:0.99736\tvalid-logloss:0.12205\tvalid-auc:0.96906\n",
      "[4100]\ttrain-logloss:0.05739\ttrain-auc:0.99755\tvalid-logloss:0.12178\tvalid-auc:0.96919\n",
      "[4200]\ttrain-logloss:0.05624\ttrain-auc:0.99775\tvalid-logloss:0.12156\tvalid-auc:0.96931\n",
      "[4300]\ttrain-logloss:0.05520\ttrain-auc:0.99790\tvalid-logloss:0.12134\tvalid-auc:0.96939\n",
      "[4400]\ttrain-logloss:0.05406\ttrain-auc:0.99808\tvalid-logloss:0.12116\tvalid-auc:0.96945\n",
      "[4500]\ttrain-logloss:0.05303\ttrain-auc:0.99822\tvalid-logloss:0.12107\tvalid-auc:0.96948\n",
      "[4600]\ttrain-logloss:0.05204\ttrain-auc:0.99836\tvalid-logloss:0.12095\tvalid-auc:0.96953\n",
      "[4700]\ttrain-logloss:0.05106\ttrain-auc:0.99847\tvalid-logloss:0.12082\tvalid-auc:0.96961\n",
      "[4800]\ttrain-logloss:0.05008\ttrain-auc:0.99859\tvalid-logloss:0.12064\tvalid-auc:0.96969\n",
      "[4900]\ttrain-logloss:0.04911\ttrain-auc:0.99870\tvalid-logloss:0.12058\tvalid-auc:0.96971\n",
      "[4995]\ttrain-logloss:0.04824\ttrain-auc:0.99880\tvalid-logloss:0.12066\tvalid-auc:0.96968\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.920417\ttraining's binary_logloss: 0.219799\tvalid_1's auc: 0.91256\tvalid_1's binary_logloss: 0.22345\n",
      "[400]\ttraining's auc: 0.940642\ttraining's binary_logloss: 0.187935\tvalid_1's auc: 0.932996\tvalid_1's binary_logloss: 0.19324\n",
      "[600]\ttraining's auc: 0.94891\ttraining's binary_logloss: 0.173473\tvalid_1's auc: 0.940353\tvalid_1's binary_logloss: 0.180366\n",
      "[800]\ttraining's auc: 0.954996\ttraining's binary_logloss: 0.163294\tvalid_1's auc: 0.945538\tvalid_1's binary_logloss: 0.171621\n",
      "[1000]\ttraining's auc: 0.959257\ttraining's binary_logloss: 0.155628\tvalid_1's auc: 0.949025\tvalid_1's binary_logloss: 0.165269\n",
      "[1200]\ttraining's auc: 0.962724\ttraining's binary_logloss: 0.149385\tvalid_1's auc: 0.951754\tvalid_1's binary_logloss: 0.16032\n",
      "[1400]\ttraining's auc: 0.965453\ttraining's binary_logloss: 0.144175\tvalid_1's auc: 0.953833\tvalid_1's binary_logloss: 0.156355\n",
      "[1600]\ttraining's auc: 0.968023\ttraining's binary_logloss: 0.139177\tvalid_1's auc: 0.955736\tvalid_1's binary_logloss: 0.152682\n",
      "[1800]\ttraining's auc: 0.97003\ttraining's binary_logloss: 0.134945\tvalid_1's auc: 0.957091\tvalid_1's binary_logloss: 0.149725\n",
      "[2000]\ttraining's auc: 0.972023\ttraining's binary_logloss: 0.131019\tvalid_1's auc: 0.958477\tvalid_1's binary_logloss: 0.147048\n",
      "[2200]\ttraining's auc: 0.973713\ttraining's binary_logloss: 0.127526\tvalid_1's auc: 0.959531\tvalid_1's binary_logloss: 0.144825\n",
      "[2400]\ttraining's auc: 0.975173\ttraining's binary_logloss: 0.124493\tvalid_1's auc: 0.960339\tvalid_1's binary_logloss: 0.143063\n",
      "[2600]\ttraining's auc: 0.976588\ttraining's binary_logloss: 0.121511\tvalid_1's auc: 0.961121\tvalid_1's binary_logloss: 0.141417\n",
      "[2800]\ttraining's auc: 0.977968\ttraining's binary_logloss: 0.118612\tvalid_1's auc: 0.96187\tvalid_1's binary_logloss: 0.139816\n",
      "[3000]\ttraining's auc: 0.979138\ttraining's binary_logloss: 0.115958\tvalid_1's auc: 0.96258\tvalid_1's binary_logloss: 0.13831\n",
      "[3200]\ttraining's auc: 0.980347\ttraining's binary_logloss: 0.113325\tvalid_1's auc: 0.963265\tvalid_1's binary_logloss: 0.136878\n",
      "[3400]\ttraining's auc: 0.981485\ttraining's binary_logloss: 0.110703\tvalid_1's auc: 0.963904\tvalid_1's binary_logloss: 0.135454\n",
      "[3600]\ttraining's auc: 0.982541\ttraining's binary_logloss: 0.108196\tvalid_1's auc: 0.964426\tvalid_1's binary_logloss: 0.134242\n",
      "[3800]\ttraining's auc: 0.983572\ttraining's binary_logloss: 0.105778\tvalid_1's auc: 0.964967\tvalid_1's binary_logloss: 0.133058\n",
      "[4000]\ttraining's auc: 0.9845\ttraining's binary_logloss: 0.103512\tvalid_1's auc: 0.965402\tvalid_1's binary_logloss: 0.132049\n",
      "[4200]\ttraining's auc: 0.985452\ttraining's binary_logloss: 0.101132\tvalid_1's auc: 0.965896\tvalid_1's binary_logloss: 0.1309\n",
      "[4400]\ttraining's auc: 0.986331\ttraining's binary_logloss: 0.0989447\tvalid_1's auc: 0.96638\tvalid_1's binary_logloss: 0.129895\n",
      "[4600]\ttraining's auc: 0.987129\ttraining's binary_logloss: 0.0968014\tvalid_1's auc: 0.966798\tvalid_1's binary_logloss: 0.128948\n",
      "[4800]\ttraining's auc: 0.987887\ttraining's binary_logloss: 0.0947424\tvalid_1's auc: 0.96716\tvalid_1's binary_logloss: 0.128062\n",
      "[5000]\ttraining's auc: 0.988616\ttraining's binary_logloss: 0.0927412\tvalid_1's auc: 0.967509\tvalid_1's binary_logloss: 0.12727\n",
      "[5200]\ttraining's auc: 0.989293\ttraining's binary_logloss: 0.0908414\tvalid_1's auc: 0.967807\tvalid_1's binary_logloss: 0.126513\n",
      "[5400]\ttraining's auc: 0.989926\ttraining's binary_logloss: 0.0889867\tvalid_1's auc: 0.968127\tvalid_1's binary_logloss: 0.12582\n",
      "[5600]\ttraining's auc: 0.990557\ttraining's binary_logloss: 0.087189\tvalid_1's auc: 0.968472\tvalid_1's binary_logloss: 0.125103\n",
      "[5800]\ttraining's auc: 0.991077\ttraining's binary_logloss: 0.0855674\tvalid_1's auc: 0.968726\tvalid_1's binary_logloss: 0.124509\n",
      "[6000]\ttraining's auc: 0.991596\ttraining's binary_logloss: 0.0839444\tvalid_1's auc: 0.969028\tvalid_1's binary_logloss: 0.123866\n",
      "[6200]\ttraining's auc: 0.992075\ttraining's binary_logloss: 0.082361\tvalid_1's auc: 0.969194\tvalid_1's binary_logloss: 0.12342\n",
      "[6400]\ttraining's auc: 0.992516\ttraining's binary_logloss: 0.0808557\tvalid_1's auc: 0.969373\tvalid_1's binary_logloss: 0.122928\n",
      "[6600]\ttraining's auc: 0.993001\ttraining's binary_logloss: 0.079198\tvalid_1's auc: 0.969579\tvalid_1's binary_logloss: 0.122331\n",
      "[6800]\ttraining's auc: 0.993473\ttraining's binary_logloss: 0.0776142\tvalid_1's auc: 0.969758\tvalid_1's binary_logloss: 0.121847\n",
      "[7000]\ttraining's auc: 0.99386\ttraining's binary_logloss: 0.0761225\tvalid_1's auc: 0.969939\tvalid_1's binary_logloss: 0.121318\n",
      "[7200]\ttraining's auc: 0.994229\ttraining's binary_logloss: 0.0747283\tvalid_1's auc: 0.970094\tvalid_1's binary_logloss: 0.120898\n",
      "[7400]\ttraining's auc: 0.99456\ttraining's binary_logloss: 0.0734219\tvalid_1's auc: 0.970202\tvalid_1's binary_logloss: 0.120575\n",
      "[7600]\ttraining's auc: 0.994854\ttraining's binary_logloss: 0.0722047\tvalid_1's auc: 0.970311\tvalid_1's binary_logloss: 0.120272\n",
      "[7800]\ttraining's auc: 0.995131\ttraining's binary_logloss: 0.0709917\tvalid_1's auc: 0.970439\tvalid_1's binary_logloss: 0.119928\n",
      "[8000]\ttraining's auc: 0.995395\ttraining's binary_logloss: 0.0698459\tvalid_1's auc: 0.970538\tvalid_1's binary_logloss: 0.119632\n",
      "[8200]\ttraining's auc: 0.99569\ttraining's binary_logloss: 0.0685209\tvalid_1's auc: 0.970679\tvalid_1's binary_logloss: 0.119219\n",
      "[8400]\ttraining's auc: 0.995942\ttraining's binary_logloss: 0.0673911\tvalid_1's auc: 0.970783\tvalid_1's binary_logloss: 0.118946\n",
      "[8600]\ttraining's auc: 0.996179\ttraining's binary_logloss: 0.0662352\tvalid_1's auc: 0.970909\tvalid_1's binary_logloss: 0.118617\n",
      "[8800]\ttraining's auc: 0.99641\ttraining's binary_logloss: 0.065153\tvalid_1's auc: 0.97098\tvalid_1's binary_logloss: 0.118388\n",
      "[9000]\ttraining's auc: 0.996614\ttraining's binary_logloss: 0.06408\tvalid_1's auc: 0.971046\tvalid_1's binary_logloss: 0.118127\n",
      "[9200]\ttraining's auc: 0.996825\ttraining's binary_logloss: 0.0630017\tvalid_1's auc: 0.971124\tvalid_1's binary_logloss: 0.117931\n",
      "[9400]\ttraining's auc: 0.997023\ttraining's binary_logloss: 0.0619298\tvalid_1's auc: 0.971181\tvalid_1's binary_logloss: 0.117724\n",
      "[9600]\ttraining's auc: 0.997227\ttraining's binary_logloss: 0.0608334\tvalid_1's auc: 0.971275\tvalid_1's binary_logloss: 0.117473\n",
      "[9800]\ttraining's auc: 0.997393\ttraining's binary_logloss: 0.0598325\tvalid_1's auc: 0.971353\tvalid_1's binary_logloss: 0.117275\n",
      "[10000]\ttraining's auc: 0.997555\ttraining's binary_logloss: 0.0589106\tvalid_1's auc: 0.971413\tvalid_1's binary_logloss: 0.117116\n",
      "[10200]\ttraining's auc: 0.997695\ttraining's binary_logloss: 0.0579821\tvalid_1's auc: 0.97144\tvalid_1's binary_logloss: 0.116995\n",
      "[10400]\ttraining's auc: 0.997823\ttraining's binary_logloss: 0.0571281\tvalid_1's auc: 0.971495\tvalid_1's binary_logloss: 0.11682\n",
      "[10600]\ttraining's auc: 0.997949\ttraining's binary_logloss: 0.0562625\tvalid_1's auc: 0.971584\tvalid_1's binary_logloss: 0.116636\n",
      "[10800]\ttraining's auc: 0.998076\ttraining's binary_logloss: 0.0553794\tvalid_1's auc: 0.971691\tvalid_1's binary_logloss: 0.11642\n",
      "[11000]\ttraining's auc: 0.998204\ttraining's binary_logloss: 0.0544698\tvalid_1's auc: 0.971757\tvalid_1's binary_logloss: 0.116264\n",
      "[11200]\ttraining's auc: 0.998316\ttraining's binary_logloss: 0.0536566\tvalid_1's auc: 0.971797\tvalid_1's binary_logloss: 0.116102\n",
      "[11400]\ttraining's auc: 0.998417\ttraining's binary_logloss: 0.0528446\tvalid_1's auc: 0.971883\tvalid_1's binary_logloss: 0.115891\n",
      "[11600]\ttraining's auc: 0.998509\ttraining's binary_logloss: 0.0520994\tvalid_1's auc: 0.971911\tvalid_1's binary_logloss: 0.115833\n",
      "[11800]\ttraining's auc: 0.998597\ttraining's binary_logloss: 0.0513514\tvalid_1's auc: 0.971933\tvalid_1's binary_logloss: 0.115749\n",
      "[12000]\ttraining's auc: 0.998687\ttraining's binary_logloss: 0.0505884\tvalid_1's auc: 0.971962\tvalid_1's binary_logloss: 0.115665\n",
      "[12200]\ttraining's auc: 0.998763\ttraining's binary_logloss: 0.0498387\tvalid_1's auc: 0.971993\tvalid_1's binary_logloss: 0.115587\n",
      "[12400]\ttraining's auc: 0.998836\ttraining's binary_logloss: 0.049091\tvalid_1's auc: 0.972054\tvalid_1's binary_logloss: 0.115436\n",
      "[12600]\ttraining's auc: 0.998912\ttraining's binary_logloss: 0.0483634\tvalid_1's auc: 0.972103\tvalid_1's binary_logloss: 0.11529\n",
      "[12800]\ttraining's auc: 0.998984\ttraining's binary_logloss: 0.0476334\tvalid_1's auc: 0.972154\tvalid_1's binary_logloss: 0.115171\n",
      "[13000]\ttraining's auc: 0.999047\ttraining's binary_logloss: 0.0469286\tvalid_1's auc: 0.972204\tvalid_1's binary_logloss: 0.115049\n",
      "[13200]\ttraining's auc: 0.999103\ttraining's binary_logloss: 0.0462888\tvalid_1's auc: 0.972224\tvalid_1's binary_logloss: 0.115005\n",
      "[13400]\ttraining's auc: 0.999164\ttraining's binary_logloss: 0.0455751\tvalid_1's auc: 0.972279\tvalid_1's binary_logloss: 0.114875\n",
      "[13600]\ttraining's auc: 0.999214\ttraining's binary_logloss: 0.0449639\tvalid_1's auc: 0.972302\tvalid_1's binary_logloss: 0.114817\n",
      "[13800]\ttraining's auc: 0.99926\ttraining's binary_logloss: 0.0443528\tvalid_1's auc: 0.972306\tvalid_1's binary_logloss: 0.114796\n",
      "[14000]\ttraining's auc: 0.999309\ttraining's binary_logloss: 0.0437307\tvalid_1's auc: 0.972304\tvalid_1's binary_logloss: 0.114777\n",
      "[14200]\ttraining's auc: 0.999351\ttraining's binary_logloss: 0.0431495\tvalid_1's auc: 0.972341\tvalid_1's binary_logloss: 0.114717\n",
      "[14400]\ttraining's auc: 0.999397\ttraining's binary_logloss: 0.04254\tvalid_1's auc: 0.972344\tvalid_1's binary_logloss: 0.114685\n",
      "[14600]\ttraining's auc: 0.999432\ttraining's binary_logloss: 0.0419659\tvalid_1's auc: 0.972389\tvalid_1's binary_logloss: 0.11459\n",
      "[14800]\ttraining's auc: 0.99947\ttraining's binary_logloss: 0.0414252\tvalid_1's auc: 0.972392\tvalid_1's binary_logloss: 0.114578\n",
      "[15000]\ttraining's auc: 0.999503\ttraining's binary_logloss: 0.0408857\tvalid_1's auc: 0.972418\tvalid_1's binary_logloss: 0.114526\n",
      "[15200]\ttraining's auc: 0.999536\ttraining's binary_logloss: 0.0403347\tvalid_1's auc: 0.972461\tvalid_1's binary_logloss: 0.114446\n",
      "[15400]\ttraining's auc: 0.999565\ttraining's binary_logloss: 0.0398267\tvalid_1's auc: 0.972483\tvalid_1's binary_logloss: 0.114426\n",
      "[15600]\ttraining's auc: 0.99959\ttraining's binary_logloss: 0.0393511\tvalid_1's auc: 0.972466\tvalid_1's binary_logloss: 0.114447\n",
      "[15800]\ttraining's auc: 0.999616\ttraining's binary_logloss: 0.0388796\tvalid_1's auc: 0.972473\tvalid_1's binary_logloss: 0.114442\n",
      "[16000]\ttraining's auc: 0.999642\ttraining's binary_logloss: 0.0383756\tvalid_1's auc: 0.972506\tvalid_1's binary_logloss: 0.114374\n",
      "[16200]\ttraining's auc: 0.999665\ttraining's binary_logloss: 0.037873\tvalid_1's auc: 0.972558\tvalid_1's binary_logloss: 0.114319\n",
      "[16400]\ttraining's auc: 0.999685\ttraining's binary_logloss: 0.0374281\tvalid_1's auc: 0.972587\tvalid_1's binary_logloss: 0.114292\n",
      "[16600]\ttraining's auc: 0.999703\ttraining's binary_logloss: 0.0370184\tvalid_1's auc: 0.972576\tvalid_1's binary_logloss: 0.11431\n",
      "[16800]\ttraining's auc: 0.99972\ttraining's binary_logloss: 0.0365771\tvalid_1's auc: 0.972563\tvalid_1's binary_logloss: 0.114367\n",
      "Early stopping, best iteration is:\n",
      "[16305]\ttraining's auc: 0.999675\ttraining's binary_logloss: 0.037647\tvalid_1's auc: 0.972582\tvalid_1's binary_logloss: 0.114278\n",
      "0:\ttest: 0.7212179\tbest: 0.7212179 (0)\ttotal: 1.13s\tremaining: 1d 7h 21m\n",
      "100:\ttest: 0.8700939\tbest: 0.8700939 (100)\ttotal: 1m 55s\tremaining: 1d 7h 45m 24s\n",
      "200:\ttest: 0.8867558\tbest: 0.8867558 (200)\ttotal: 3m 50s\tremaining: 1d 7h 47m 32s\n",
      "300:\ttest: 0.9033301\tbest: 0.9033301 (300)\ttotal: 5m 45s\tremaining: 1d 7h 44m 55s\n",
      "400:\ttest: 0.9157295\tbest: 0.9157295 (400)\ttotal: 7m 40s\tremaining: 1d 7h 44m 38s\n",
      "500:\ttest: 0.9244305\tbest: 0.9244305 (500)\ttotal: 9m 34s\tremaining: 1d 7h 42m 3s\n",
      "600:\ttest: 0.9313143\tbest: 0.9313143 (600)\ttotal: 11m 29s\tremaining: 1d 7h 40m 8s\n",
      "700:\ttest: 0.9361450\tbest: 0.9361450 (700)\ttotal: 13m 24s\tremaining: 1d 7h 39m 13s\n",
      "800:\ttest: 0.9402858\tbest: 0.9402858 (800)\ttotal: 15m 19s\tremaining: 1d 7h 36m 53s\n",
      "900:\ttest: 0.9436349\tbest: 0.9436349 (900)\ttotal: 17m 14s\tremaining: 1d 7h 36m 25s\n",
      "1000:\ttest: 0.9458941\tbest: 0.9458941 (1000)\ttotal: 19m 9s\tremaining: 1d 7h 35m 32s\n",
      "1100:\ttest: 0.9479970\tbest: 0.9479970 (1100)\ttotal: 21m 6s\tremaining: 1d 7h 35m 28s\n",
      "1200:\ttest: 0.9496233\tbest: 0.9496233 (1200)\ttotal: 23m\tremaining: 1d 7h 33m 21s\n",
      "1300:\ttest: 0.9512463\tbest: 0.9512463 (1300)\ttotal: 24m 56s\tremaining: 1d 7h 31m 35s\n",
      "1400:\ttest: 0.9522955\tbest: 0.9522955 (1400)\ttotal: 26m 50s\tremaining: 1d 7h 29m 17s\n",
      "1500:\ttest: 0.9533479\tbest: 0.9533496 (1498)\ttotal: 28m 45s\tremaining: 1d 7h 27m 14s\n",
      "1600:\ttest: 0.9540525\tbest: 0.9540525 (1600)\ttotal: 30m 40s\tremaining: 1d 7h 25m 22s\n",
      "1700:\ttest: 0.9546143\tbest: 0.9546148 (1699)\ttotal: 32m 35s\tremaining: 1d 7h 23m 9s\n",
      "1800:\ttest: 0.9552235\tbest: 0.9552235 (1800)\ttotal: 34m 29s\tremaining: 1d 7h 20m 41s\n",
      "1900:\ttest: 0.9556922\tbest: 0.9556924 (1899)\ttotal: 36m 24s\tremaining: 1d 7h 18m 48s\n",
      "2000:\ttest: 0.9562213\tbest: 0.9562213 (1999)\ttotal: 38m 19s\tremaining: 1d 7h 16m 56s\n",
      "2100:\ttest: 0.9566615\tbest: 0.9566640 (2094)\ttotal: 40m 14s\tremaining: 1d 7h 15m 14s\n",
      "2200:\ttest: 0.9568462\tbest: 0.9568462 (2200)\ttotal: 42m 9s\tremaining: 1d 7h 13m 14s\n",
      "2300:\ttest: 0.9573354\tbest: 0.9573354 (2300)\ttotal: 44m 4s\tremaining: 1d 7h 11m 6s\n",
      "2400:\ttest: 0.9575704\tbest: 0.9575704 (2400)\ttotal: 45m 58s\tremaining: 1d 7h 8m 44s\n",
      "2500:\ttest: 0.9577807\tbest: 0.9577830 (2493)\ttotal: 47m 53s\tremaining: 1d 7h 6m 49s\n",
      "2600:\ttest: 0.9580104\tbest: 0.9580111 (2597)\ttotal: 49m 47s\tremaining: 1d 7h 4m 34s\n",
      "2700:\ttest: 0.9583203\tbest: 0.9583203 (2700)\ttotal: 51m 42s\tremaining: 1d 7h 2m 43s\n",
      "2800:\ttest: 0.9585403\tbest: 0.9585403 (2800)\ttotal: 53m 37s\tremaining: 1d 7h 36s\n",
      "2900:\ttest: 0.9586904\tbest: 0.9586904 (2900)\ttotal: 55m 31s\tremaining: 1d 6h 58m 24s\n",
      "3000:\ttest: 0.9588678\tbest: 0.9588678 (3000)\ttotal: 57m 16s\tremaining: 1d 6h 51m 24s\n",
      "3100:\ttest: 0.9589670\tbest: 0.9589681 (3087)\ttotal: 58m 55s\tremaining: 1d 6h 41m 23s\n",
      "3200:\ttest: 0.9590507\tbest: 0.9590534 (3197)\ttotal: 1h 40s\tremaining: 1d 6h 35m 2s\n",
      "3300:\ttest: 0.9591869\tbest: 0.9591873 (3299)\ttotal: 1h 2m 35s\tremaining: 1d 6h 33m 35s\n",
      "3400:\ttest: 0.9592477\tbest: 0.9592477 (3400)\ttotal: 1h 4m 29s\tremaining: 1d 6h 31m 59s\n",
      "3500:\ttest: 0.9593224\tbest: 0.9593243 (3497)\ttotal: 1h 6m 24s\tremaining: 1d 6h 30m 22s\n",
      "3600:\ttest: 0.9593905\tbest: 0.9593907 (3599)\ttotal: 1h 8m 18s\tremaining: 1d 6h 28m 40s\n",
      "3700:\ttest: 0.9594633\tbest: 0.9594644 (3698)\ttotal: 1h 10m 12s\tremaining: 1d 6h 26m 59s\n",
      "3800:\ttest: 0.9596319\tbest: 0.9596319 (3800)\ttotal: 1h 12m 7s\tremaining: 1d 6h 25m 28s\n",
      "3900:\ttest: 0.9597417\tbest: 0.9597417 (3900)\ttotal: 1h 14m 2s\tremaining: 1d 6h 23m 49s\n",
      "4000:\ttest: 0.9598232\tbest: 0.9598232 (4000)\ttotal: 1h 15m 56s\tremaining: 1d 6h 21m 57s\n",
      "4100:\ttest: 0.9598910\tbest: 0.9598945 (4092)\ttotal: 1h 17m 50s\tremaining: 1d 6h 20m 19s\n",
      "4200:\ttest: 0.9599556\tbest: 0.9599564 (4198)\ttotal: 1h 19m 45s\tremaining: 1d 6h 18m 45s\n",
      "4300:\ttest: 0.9600040\tbest: 0.9600052 (4292)\ttotal: 1h 21m 37s\tremaining: 1d 6h 16m 18s\n",
      "4400:\ttest: 0.9600803\tbest: 0.9600820 (4397)\ttotal: 1h 23m 32s\tremaining: 1d 6h 14m 41s\n",
      "4500:\ttest: 0.9601669\tbest: 0.9601673 (4499)\ttotal: 1h 25m 27s\tremaining: 1d 6h 13m 4s\n",
      "4600:\ttest: 0.9602987\tbest: 0.9603003 (4597)\ttotal: 1h 27m 21s\tremaining: 1d 6h 11m 18s\n",
      "4700:\ttest: 0.9604045\tbest: 0.9604045 (4700)\ttotal: 1h 29m 15s\tremaining: 1d 6h 9m 31s\n",
      "4800:\ttest: 0.9605261\tbest: 0.9605284 (4792)\ttotal: 1h 31m 9s\tremaining: 1d 6h 7m 31s\n",
      "4900:\ttest: 0.9605870\tbest: 0.9605912 (4878)\ttotal: 1h 33m 3s\tremaining: 1d 6h 5m 34s\n",
      "5000:\ttest: 0.9606337\tbest: 0.9606337 (5000)\ttotal: 1h 34m 56s\tremaining: 1d 6h 3m 33s\n",
      "5100:\ttest: 0.9606655\tbest: 0.9606673 (5097)\ttotal: 1h 36m 50s\tremaining: 1d 6h 1m 45s\n",
      "5200:\ttest: 0.9606888\tbest: 0.9606905 (5196)\ttotal: 1h 38m 44s\tremaining: 1d 5h 59m 55s\n",
      "5300:\ttest: 0.9607283\tbest: 0.9607287 (5290)\ttotal: 1h 40m 38s\tremaining: 1d 5h 57m 46s\n",
      "5400:\ttest: 0.9607616\tbest: 0.9607620 (5393)\ttotal: 1h 42m 31s\tremaining: 1d 5h 55m 45s\n",
      "5500:\ttest: 0.9607972\tbest: 0.9607986 (5497)\ttotal: 1h 44m 25s\tremaining: 1d 5h 53m 51s\n",
      "5600:\ttest: 0.9608260\tbest: 0.9608269 (5597)\ttotal: 1h 46m 19s\tremaining: 1d 5h 52m 4s\n",
      "5700:\ttest: 0.9608421\tbest: 0.9608442 (5675)\ttotal: 1h 48m 14s\tremaining: 1d 5h 50m 17s\n",
      "5800:\ttest: 0.9608918\tbest: 0.9608919 (5799)\ttotal: 1h 50m 7s\tremaining: 1d 5h 48m 22s\n",
      "5900:\ttest: 0.9609043\tbest: 0.9609043 (5900)\ttotal: 1h 52m\tremaining: 1d 5h 46m 1s\n",
      "6000:\ttest: 0.9609150\tbest: 0.9609154 (5999)\ttotal: 1h 53m 51s\tremaining: 1d 5h 43m 33s\n",
      "6100:\ttest: 0.9609282\tbest: 0.9609291 (6095)\ttotal: 1h 55m 44s\tremaining: 1d 5h 41m 19s\n",
      "6200:\ttest: 0.9609665\tbest: 0.9609665 (6200)\ttotal: 1h 57m 38s\tremaining: 1d 5h 39m 31s\n",
      "6300:\ttest: 0.9609809\tbest: 0.9609904 (6233)\ttotal: 1h 59m 30s\tremaining: 1d 5h 37m 9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9609904139\n",
      "bestIteration = 6233\n",
      "\n",
      "Shrink model to first 6234 iterations.\n",
      "[13:23:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.67268\ttrain-auc:0.71511\tvalid-logloss:0.67271\tvalid-auc:0.71244\n",
      "[100]\ttrain-logloss:0.22576\ttrain-auc:0.91630\tvalid-logloss:0.22909\tvalid-auc:0.90924\n",
      "[200]\ttrain-logloss:0.18189\ttrain-auc:0.94376\tvalid-logloss:0.18797\tvalid-auc:0.93598\n",
      "[300]\ttrain-logloss:0.16417\ttrain-auc:0.95414\tvalid-logloss:0.17221\tvalid-auc:0.94544\n",
      "[400]\ttrain-logloss:0.15339\ttrain-auc:0.96009\tvalid-logloss:0.16300\tvalid-auc:0.95062\n",
      "[500]\ttrain-logloss:0.14550\ttrain-auc:0.96399\tvalid-logloss:0.15681\tvalid-auc:0.95368\n",
      "[600]\ttrain-logloss:0.13865\ttrain-auc:0.96734\tvalid-logloss:0.15160\tvalid-auc:0.95628\n",
      "[700]\ttrain-logloss:0.13323\ttrain-auc:0.97002\tvalid-logloss:0.14780\tvalid-auc:0.95812\n",
      "[800]\ttrain-logloss:0.12870\ttrain-auc:0.97219\tvalid-logloss:0.14504\tvalid-auc:0.95933\n",
      "[900]\ttrain-logloss:0.12450\ttrain-auc:0.97426\tvalid-logloss:0.14275\tvalid-auc:0.96025\n",
      "[1000]\ttrain-logloss:0.12080\ttrain-auc:0.97603\tvalid-logloss:0.14069\tvalid-auc:0.96122\n",
      "[1100]\ttrain-logloss:0.11699\ttrain-auc:0.97786\tvalid-logloss:0.13868\tvalid-auc:0.96223\n",
      "[1200]\ttrain-logloss:0.11333\ttrain-auc:0.97959\tvalid-logloss:0.13676\tvalid-auc:0.96313\n",
      "[1300]\ttrain-logloss:0.11020\ttrain-auc:0.98097\tvalid-logloss:0.13534\tvalid-auc:0.96375\n",
      "[1400]\ttrain-logloss:0.10701\ttrain-auc:0.98240\tvalid-logloss:0.13385\tvalid-auc:0.96443\n",
      "[1500]\ttrain-logloss:0.10413\ttrain-auc:0.98362\tvalid-logloss:0.13258\tvalid-auc:0.96503\n",
      "[1600]\ttrain-logloss:0.10156\ttrain-auc:0.98468\tvalid-logloss:0.13160\tvalid-auc:0.96545\n",
      "[1700]\ttrain-logloss:0.09889\ttrain-auc:0.98577\tvalid-logloss:0.13045\tvalid-auc:0.96597\n",
      "[1800]\ttrain-logloss:0.09623\ttrain-auc:0.98683\tvalid-logloss:0.12933\tvalid-auc:0.96652\n",
      "[1900]\ttrain-logloss:0.09379\ttrain-auc:0.98776\tvalid-logloss:0.12837\tvalid-auc:0.96693\n",
      "[2000]\ttrain-logloss:0.09152\ttrain-auc:0.98858\tvalid-logloss:0.12764\tvalid-auc:0.96724\n",
      "[2100]\ttrain-logloss:0.08922\ttrain-auc:0.98938\tvalid-logloss:0.12687\tvalid-auc:0.96752\n",
      "[2200]\ttrain-logloss:0.08705\ttrain-auc:0.99013\tvalid-logloss:0.12606\tvalid-auc:0.96793\n",
      "[2300]\ttrain-logloss:0.08506\ttrain-auc:0.99079\tvalid-logloss:0.12534\tvalid-auc:0.96825\n",
      "[2400]\ttrain-logloss:0.08292\ttrain-auc:0.99146\tvalid-logloss:0.12464\tvalid-auc:0.96854\n",
      "[2500]\ttrain-logloss:0.08098\ttrain-auc:0.99207\tvalid-logloss:0.12402\tvalid-auc:0.96878\n",
      "[2600]\ttrain-logloss:0.07920\ttrain-auc:0.99261\tvalid-logloss:0.12356\tvalid-auc:0.96895\n",
      "[2700]\ttrain-logloss:0.07746\ttrain-auc:0.99310\tvalid-logloss:0.12313\tvalid-auc:0.96906\n",
      "[2800]\ttrain-logloss:0.07571\ttrain-auc:0.99357\tvalid-logloss:0.12270\tvalid-auc:0.96924\n",
      "[2900]\ttrain-logloss:0.07410\ttrain-auc:0.99401\tvalid-logloss:0.12228\tvalid-auc:0.96939\n",
      "[3000]\ttrain-logloss:0.07241\ttrain-auc:0.99444\tvalid-logloss:0.12180\tvalid-auc:0.96960\n",
      "[3100]\ttrain-logloss:0.07095\ttrain-auc:0.99481\tvalid-logloss:0.12167\tvalid-auc:0.96956\n",
      "[3121]\ttrain-logloss:0.07067\ttrain-auc:0.99487\tvalid-logloss:0.12160\tvalid-auc:0.96958\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.917926\ttraining's binary_logloss: 0.220906\tvalid_1's auc: 0.912926\tvalid_1's binary_logloss: 0.222765\n",
      "[400]\ttraining's auc: 0.939849\ttraining's binary_logloss: 0.18899\tvalid_1's auc: 0.933363\tvalid_1's binary_logloss: 0.192487\n",
      "[600]\ttraining's auc: 0.948541\ttraining's binary_logloss: 0.173775\tvalid_1's auc: 0.940516\tvalid_1's binary_logloss: 0.178927\n",
      "[800]\ttraining's auc: 0.954536\ttraining's binary_logloss: 0.163985\tvalid_1's auc: 0.945369\tvalid_1's binary_logloss: 0.170524\n",
      "[1000]\ttraining's auc: 0.959104\ttraining's binary_logloss: 0.156167\tvalid_1's auc: 0.949054\tvalid_1's binary_logloss: 0.164017\n",
      "[1200]\ttraining's auc: 0.962705\ttraining's binary_logloss: 0.149529\tvalid_1's auc: 0.951948\tvalid_1's binary_logloss: 0.158543\n",
      "[1400]\ttraining's auc: 0.96546\ttraining's binary_logloss: 0.144443\tvalid_1's auc: 0.953899\tvalid_1's binary_logloss: 0.154782\n",
      "[1600]\ttraining's auc: 0.967674\ttraining's binary_logloss: 0.139824\tvalid_1's auc: 0.955479\tvalid_1's binary_logloss: 0.151385\n",
      "[1800]\ttraining's auc: 0.969794\ttraining's binary_logloss: 0.135598\tvalid_1's auc: 0.956888\tvalid_1's binary_logloss: 0.148524\n",
      "[2000]\ttraining's auc: 0.97175\ttraining's binary_logloss: 0.131835\tvalid_1's auc: 0.958158\tvalid_1's binary_logloss: 0.14603\n",
      "[2200]\ttraining's auc: 0.973447\ttraining's binary_logloss: 0.128422\tvalid_1's auc: 0.959151\tvalid_1's binary_logloss: 0.143836\n",
      "[2400]\ttraining's auc: 0.975109\ttraining's binary_logloss: 0.125114\tvalid_1's auc: 0.960217\tvalid_1's binary_logloss: 0.141763\n",
      "[2600]\ttraining's auc: 0.976663\ttraining's binary_logloss: 0.121719\tvalid_1's auc: 0.961027\tvalid_1's binary_logloss: 0.13986\n",
      "[2800]\ttraining's auc: 0.978111\ttraining's binary_logloss: 0.118682\tvalid_1's auc: 0.961841\tvalid_1's binary_logloss: 0.138153\n",
      "[3000]\ttraining's auc: 0.97934\ttraining's binary_logloss: 0.11596\tvalid_1's auc: 0.962571\tvalid_1's binary_logloss: 0.136596\n",
      "[3200]\ttraining's auc: 0.980536\ttraining's binary_logloss: 0.113251\tvalid_1's auc: 0.963144\tvalid_1's binary_logloss: 0.135206\n",
      "[3400]\ttraining's auc: 0.981652\ttraining's binary_logloss: 0.1107\tvalid_1's auc: 0.963696\tvalid_1's binary_logloss: 0.13397\n",
      "[3600]\ttraining's auc: 0.982716\ttraining's binary_logloss: 0.108305\tvalid_1's auc: 0.964173\tvalid_1's binary_logloss: 0.132896\n",
      "[3800]\ttraining's auc: 0.983775\ttraining's binary_logloss: 0.105782\tvalid_1's auc: 0.964824\tvalid_1's binary_logloss: 0.131582\n",
      "[4000]\ttraining's auc: 0.984708\ttraining's binary_logloss: 0.103616\tvalid_1's auc: 0.965296\tvalid_1's binary_logloss: 0.13063\n",
      "[4200]\ttraining's auc: 0.985537\ttraining's binary_logloss: 0.101479\tvalid_1's auc: 0.965654\tvalid_1's binary_logloss: 0.129737\n",
      "[4400]\ttraining's auc: 0.986338\ttraining's binary_logloss: 0.0994906\tvalid_1's auc: 0.966059\tvalid_1's binary_logloss: 0.128905\n",
      "[4600]\ttraining's auc: 0.987124\ttraining's binary_logloss: 0.0974388\tvalid_1's auc: 0.966524\tvalid_1's binary_logloss: 0.127954\n",
      "[4800]\ttraining's auc: 0.987913\ttraining's binary_logloss: 0.0952515\tvalid_1's auc: 0.966972\tvalid_1's binary_logloss: 0.12698\n",
      "[5000]\ttraining's auc: 0.988595\ttraining's binary_logloss: 0.0933166\tvalid_1's auc: 0.967271\tvalid_1's binary_logloss: 0.126266\n",
      "[5200]\ttraining's auc: 0.989223\ttraining's binary_logloss: 0.091524\tvalid_1's auc: 0.967594\tvalid_1's binary_logloss: 0.125522\n",
      "[5400]\ttraining's auc: 0.989861\ttraining's binary_logloss: 0.0896523\tvalid_1's auc: 0.967899\tvalid_1's binary_logloss: 0.124804\n",
      "[5600]\ttraining's auc: 0.990462\ttraining's binary_logloss: 0.0878291\tvalid_1's auc: 0.96815\tvalid_1's binary_logloss: 0.124177\n",
      "[5800]\ttraining's auc: 0.991003\ttraining's binary_logloss: 0.0861769\tvalid_1's auc: 0.968392\tvalid_1's binary_logloss: 0.123595\n",
      "[6000]\ttraining's auc: 0.991502\ttraining's binary_logloss: 0.0845412\tvalid_1's auc: 0.968636\tvalid_1's binary_logloss: 0.122983\n",
      "[6200]\ttraining's auc: 0.992003\ttraining's binary_logloss: 0.0829111\tvalid_1's auc: 0.968877\tvalid_1's binary_logloss: 0.122408\n",
      "[6400]\ttraining's auc: 0.992492\ttraining's binary_logloss: 0.0812477\tvalid_1's auc: 0.969122\tvalid_1's binary_logloss: 0.121832\n",
      "[6600]\ttraining's auc: 0.992907\ttraining's binary_logloss: 0.0797267\tvalid_1's auc: 0.969351\tvalid_1's binary_logloss: 0.12129\n",
      "[6800]\ttraining's auc: 0.993347\ttraining's binary_logloss: 0.0781365\tvalid_1's auc: 0.96959\tvalid_1's binary_logloss: 0.120681\n",
      "[7000]\ttraining's auc: 0.993743\ttraining's binary_logloss: 0.0767433\tvalid_1's auc: 0.969751\tvalid_1's binary_logloss: 0.120291\n",
      "[7200]\ttraining's auc: 0.994127\ttraining's binary_logloss: 0.0753223\tvalid_1's auc: 0.969915\tvalid_1's binary_logloss: 0.119868\n",
      "[7400]\ttraining's auc: 0.994477\ttraining's binary_logloss: 0.0739363\tvalid_1's auc: 0.970093\tvalid_1's binary_logloss: 0.11945\n",
      "[7600]\ttraining's auc: 0.994783\ttraining's binary_logloss: 0.0726764\tvalid_1's auc: 0.970222\tvalid_1's binary_logloss: 0.11911\n",
      "[7800]\ttraining's auc: 0.995082\ttraining's binary_logloss: 0.0714104\tvalid_1's auc: 0.970426\tvalid_1's binary_logloss: 0.118685\n",
      "[8000]\ttraining's auc: 0.995351\ttraining's binary_logloss: 0.0702568\tvalid_1's auc: 0.970503\tvalid_1's binary_logloss: 0.11848\n",
      "[8200]\ttraining's auc: 0.995632\ttraining's binary_logloss: 0.0690205\tvalid_1's auc: 0.97063\tvalid_1's binary_logloss: 0.118165\n",
      "[8400]\ttraining's auc: 0.995866\ttraining's binary_logloss: 0.0679119\tvalid_1's auc: 0.970761\tvalid_1's binary_logloss: 0.117813\n",
      "[8600]\ttraining's auc: 0.996112\ttraining's binary_logloss: 0.0667549\tvalid_1's auc: 0.970829\tvalid_1's binary_logloss: 0.117547\n",
      "[8800]\ttraining's auc: 0.99634\ttraining's binary_logloss: 0.0656391\tvalid_1's auc: 0.97092\tvalid_1's binary_logloss: 0.117283\n",
      "[9000]\ttraining's auc: 0.99655\ttraining's binary_logloss: 0.0646029\tvalid_1's auc: 0.971012\tvalid_1's binary_logloss: 0.117052\n",
      "[9200]\ttraining's auc: 0.996761\ttraining's binary_logloss: 0.0635204\tvalid_1's auc: 0.971106\tvalid_1's binary_logloss: 0.116826\n",
      "[9400]\ttraining's auc: 0.996957\ttraining's binary_logloss: 0.0624458\tvalid_1's auc: 0.971211\tvalid_1's binary_logloss: 0.116527\n",
      "[9600]\ttraining's auc: 0.99715\ttraining's binary_logloss: 0.0614439\tvalid_1's auc: 0.97128\tvalid_1's binary_logloss: 0.116354\n",
      "[9800]\ttraining's auc: 0.997307\ttraining's binary_logloss: 0.0604912\tvalid_1's auc: 0.971358\tvalid_1's binary_logloss: 0.116144\n",
      "[10000]\ttraining's auc: 0.997472\ttraining's binary_logloss: 0.0594855\tvalid_1's auc: 0.971432\tvalid_1's binary_logloss: 0.115942\n",
      "[10200]\ttraining's auc: 0.997635\ttraining's binary_logloss: 0.0584896\tvalid_1's auc: 0.971514\tvalid_1's binary_logloss: 0.115728\n",
      "[10400]\ttraining's auc: 0.997797\ttraining's binary_logloss: 0.0574835\tvalid_1's auc: 0.971598\tvalid_1's binary_logloss: 0.115446\n",
      "[10600]\ttraining's auc: 0.997931\ttraining's binary_logloss: 0.0565584\tvalid_1's auc: 0.971692\tvalid_1's binary_logloss: 0.115163\n",
      "[10800]\ttraining's auc: 0.998058\ttraining's binary_logloss: 0.0556638\tvalid_1's auc: 0.971715\tvalid_1's binary_logloss: 0.115088\n",
      "[11000]\ttraining's auc: 0.998183\ttraining's binary_logloss: 0.0547693\tvalid_1's auc: 0.971787\tvalid_1's binary_logloss: 0.114902\n",
      "[11200]\ttraining's auc: 0.998304\ttraining's binary_logloss: 0.0538731\tvalid_1's auc: 0.971847\tvalid_1's binary_logloss: 0.114708\n",
      "[11400]\ttraining's auc: 0.9984\ttraining's binary_logloss: 0.0530871\tvalid_1's auc: 0.971888\tvalid_1's binary_logloss: 0.114589\n",
      "[11600]\ttraining's auc: 0.998489\ttraining's binary_logloss: 0.0523141\tvalid_1's auc: 0.97195\tvalid_1's binary_logloss: 0.114426\n",
      "[11800]\ttraining's auc: 0.998589\ttraining's binary_logloss: 0.0515356\tvalid_1's auc: 0.972003\tvalid_1's binary_logloss: 0.114306\n",
      "[12000]\ttraining's auc: 0.998675\ttraining's binary_logloss: 0.0508059\tvalid_1's auc: 0.972012\tvalid_1's binary_logloss: 0.114258\n",
      "[12200]\ttraining's auc: 0.99875\ttraining's binary_logloss: 0.0500966\tvalid_1's auc: 0.972054\tvalid_1's binary_logloss: 0.11413\n",
      "[12400]\ttraining's auc: 0.998834\ttraining's binary_logloss: 0.0493249\tvalid_1's auc: 0.972133\tvalid_1's binary_logloss: 0.113966\n",
      "[12600]\ttraining's auc: 0.998909\ttraining's binary_logloss: 0.0486178\tvalid_1's auc: 0.972126\tvalid_1's binary_logloss: 0.113926\n",
      "[12800]\ttraining's auc: 0.99898\ttraining's binary_logloss: 0.0479281\tvalid_1's auc: 0.972136\tvalid_1's binary_logloss: 0.11389\n",
      "[13000]\ttraining's auc: 0.999048\ttraining's binary_logloss: 0.0472251\tvalid_1's auc: 0.972166\tvalid_1's binary_logloss: 0.113816\n",
      "[13200]\ttraining's auc: 0.999108\ttraining's binary_logloss: 0.0465525\tvalid_1's auc: 0.972204\tvalid_1's binary_logloss: 0.113731\n",
      "[13400]\ttraining's auc: 0.999162\ttraining's binary_logloss: 0.0458979\tvalid_1's auc: 0.972245\tvalid_1's binary_logloss: 0.11364\n",
      "[13600]\ttraining's auc: 0.999214\ttraining's binary_logloss: 0.045258\tvalid_1's auc: 0.972242\tvalid_1's binary_logloss: 0.113582\n",
      "[13800]\ttraining's auc: 0.99926\ttraining's binary_logloss: 0.0446584\tvalid_1's auc: 0.972274\tvalid_1's binary_logloss: 0.113494\n",
      "[14000]\ttraining's auc: 0.999307\ttraining's binary_logloss: 0.0440456\tvalid_1's auc: 0.972296\tvalid_1's binary_logloss: 0.113433\n",
      "[14200]\ttraining's auc: 0.999353\ttraining's binary_logloss: 0.0434378\tvalid_1's auc: 0.972311\tvalid_1's binary_logloss: 0.113383\n",
      "[14400]\ttraining's auc: 0.999389\ttraining's binary_logloss: 0.0428834\tvalid_1's auc: 0.972333\tvalid_1's binary_logloss: 0.113324\n",
      "[14600]\ttraining's auc: 0.999427\ttraining's binary_logloss: 0.0423427\tvalid_1's auc: 0.972319\tvalid_1's binary_logloss: 0.113392\n",
      "[14800]\ttraining's auc: 0.999464\ttraining's binary_logloss: 0.0418072\tvalid_1's auc: 0.972335\tvalid_1's binary_logloss: 0.11335\n",
      "Early stopping, best iteration is:\n",
      "[14350]\ttraining's auc: 0.999382\ttraining's binary_logloss: 0.0430064\tvalid_1's auc: 0.972345\tvalid_1's binary_logloss: 0.113298\n",
      "0:\ttest: 0.7182533\tbest: 0.7182533 (0)\ttotal: 1.14s\tremaining: 1d 7h 32m 20s\n",
      "100:\ttest: 0.8684889\tbest: 0.8684889 (100)\ttotal: 1m 54s\tremaining: 1d 7h 24m 12s\n",
      "200:\ttest: 0.8862153\tbest: 0.8862411 (199)\ttotal: 3m 48s\tremaining: 1d 7h 32m 48s\n",
      "300:\ttest: 0.9030261\tbest: 0.9030261 (300)\ttotal: 5m 44s\tremaining: 1d 7h 42m 52s\n",
      "400:\ttest: 0.9146085\tbest: 0.9146085 (400)\ttotal: 7m 40s\tremaining: 1d 7h 44m 57s\n",
      "500:\ttest: 0.9230965\tbest: 0.9230965 (500)\ttotal: 9m 35s\tremaining: 1d 7h 46m 2s\n",
      "600:\ttest: 0.9302841\tbest: 0.9302841 (600)\ttotal: 11m 31s\tremaining: 1d 7h 45m 25s\n",
      "700:\ttest: 0.9355477\tbest: 0.9355477 (700)\ttotal: 13m 26s\tremaining: 1d 7h 44m 7s\n",
      "800:\ttest: 0.9393219\tbest: 0.9393219 (800)\ttotal: 15m 23s\tremaining: 1d 7h 46m 30s\n",
      "900:\ttest: 0.9423784\tbest: 0.9423784 (900)\ttotal: 17m 19s\tremaining: 1d 7h 46m 20s\n",
      "1000:\ttest: 0.9447419\tbest: 0.9447419 (1000)\ttotal: 19m 16s\tremaining: 1d 7h 45m 47s\n",
      "1100:\ttest: 0.9472407\tbest: 0.9472407 (1100)\ttotal: 20m 59s\tremaining: 1d 7h 25m 35s\n",
      "1200:\ttest: 0.9492951\tbest: 0.9492951 (1200)\ttotal: 22m 40s\tremaining: 1d 7h 5m 1s\n",
      "1300:\ttest: 0.9509861\tbest: 0.9509861 (1300)\ttotal: 24m 20s\tremaining: 1d 6h 46m 55s\n",
      "1400:\ttest: 0.9524167\tbest: 0.9524167 (1400)\ttotal: 26m 1s\tremaining: 1d 6h 31m 35s\n",
      "1500:\ttest: 0.9536609\tbest: 0.9536609 (1500)\ttotal: 27m 43s\tremaining: 1d 6h 19m 16s\n",
      "1600:\ttest: 0.9544446\tbest: 0.9544446 (1600)\ttotal: 29m 26s\tremaining: 1d 6h 9m 9s\n",
      "1700:\ttest: 0.9550947\tbest: 0.9550947 (1699)\ttotal: 31m 7s\tremaining: 1d 5h 58m 19s\n",
      "1800:\ttest: 0.9557352\tbest: 0.9557369 (1799)\ttotal: 32m 48s\tremaining: 1d 5h 48m 56s\n",
      "1900:\ttest: 0.9563524\tbest: 0.9563524 (1900)\ttotal: 34m 31s\tremaining: 1d 5h 41m 52s\n",
      "2000:\ttest: 0.9569266\tbest: 0.9569268 (1999)\ttotal: 36m 13s\tremaining: 1d 5h 34m 31s\n",
      "2100:\ttest: 0.9571783\tbest: 0.9571783 (2100)\ttotal: 37m 56s\tremaining: 1d 5h 27m 36s\n",
      "2200:\ttest: 0.9578099\tbest: 0.9578099 (2200)\ttotal: 39m 38s\tremaining: 1d 5h 21m 24s\n",
      "2300:\ttest: 0.9581849\tbest: 0.9581889 (2296)\ttotal: 41m 20s\tremaining: 1d 5h 15m 18s\n",
      "2400:\ttest: 0.9583252\tbest: 0.9583278 (2399)\ttotal: 43m 2s\tremaining: 1d 5h 9m 32s\n",
      "2500:\ttest: 0.9584373\tbest: 0.9584373 (2500)\ttotal: 44m 44s\tremaining: 1d 5h 4m\n",
      "2600:\ttest: 0.9585563\tbest: 0.9585563 (2600)\ttotal: 46m 26s\tremaining: 1d 4h 58m 55s\n",
      "2700:\ttest: 0.9587396\tbest: 0.9587401 (2698)\ttotal: 48m 7s\tremaining: 1d 4h 53m 53s\n",
      "2800:\ttest: 0.9591562\tbest: 0.9591562 (2800)\ttotal: 49m 50s\tremaining: 1d 4h 49m 31s\n",
      "2900:\ttest: 0.9595659\tbest: 0.9595659 (2900)\ttotal: 51m 33s\tremaining: 1d 4h 45m 43s\n",
      "3000:\ttest: 0.9597433\tbest: 0.9597435 (2999)\ttotal: 53m 15s\tremaining: 1d 4h 41m 32s\n",
      "3100:\ttest: 0.9598647\tbest: 0.9598656 (3099)\ttotal: 54m 57s\tremaining: 1d 4h 37m 32s\n",
      "3200:\ttest: 0.9599897\tbest: 0.9599901 (3196)\ttotal: 56m 38s\tremaining: 1d 4h 32m 44s\n",
      "3300:\ttest: 0.9601465\tbest: 0.9601465 (3300)\ttotal: 58m 19s\tremaining: 1d 4h 28m 20s\n",
      "3400:\ttest: 0.9603777\tbest: 0.9603777 (3400)\ttotal: 1h\tremaining: 1d 4h 24m 12s\n",
      "3500:\ttest: 0.9604813\tbest: 0.9604828 (3497)\ttotal: 1h 1m 39s\tremaining: 1d 4h 19m 34s\n",
      "3600:\ttest: 0.9607266\tbest: 0.9607273 (3595)\ttotal: 1h 3m 21s\tremaining: 1d 4h 16m 8s\n",
      "3700:\ttest: 0.9607608\tbest: 0.9607678 (3685)\ttotal: 1h 5m 3s\tremaining: 1d 4h 12m 52s\n",
      "3800:\ttest: 0.9607877\tbest: 0.9607888 (3791)\ttotal: 1h 6m 45s\tremaining: 1d 4h 9m 35s\n",
      "3900:\ttest: 0.9608029\tbest: 0.9608029 (3900)\ttotal: 1h 8m 24s\tremaining: 1d 4h 5m 1s\n",
      "4000:\ttest: 0.9608425\tbest: 0.9608447 (3988)\ttotal: 1h 10m 4s\tremaining: 1d 4h 1m 15s\n",
      "4100:\ttest: 0.9608601\tbest: 0.9608602 (4098)\ttotal: 1h 11m 43s\tremaining: 1d 3h 57m 23s\n",
      "4200:\ttest: 0.9608814\tbest: 0.9608830 (4197)\ttotal: 1h 13m 24s\tremaining: 1d 3h 54m 2s\n",
      "4300:\ttest: 0.9609002\tbest: 0.9609030 (4274)\ttotal: 1h 15m 5s\tremaining: 1d 3h 50m 41s\n",
      "4400:\ttest: 0.9609098\tbest: 0.9609098 (4398)\ttotal: 1h 16m 44s\tremaining: 1d 3h 46m 48s\n",
      "4500:\ttest: 0.9609329\tbest: 0.9609330 (4498)\ttotal: 1h 18m 23s\tremaining: 1d 3h 43m 7s\n",
      "4600:\ttest: 0.9609641\tbest: 0.9609641 (4600)\ttotal: 1h 20m 4s\tremaining: 1d 3h 40m 18s\n",
      "4700:\ttest: 0.9610208\tbest: 0.9610217 (4699)\ttotal: 1h 21m 45s\tremaining: 1d 3h 37m 33s\n",
      "4800:\ttest: 0.9611134\tbest: 0.9611134 (4800)\ttotal: 1h 23m 27s\tremaining: 1d 3h 34m 45s\n",
      "4900:\ttest: 0.9611780\tbest: 0.9611780 (4900)\ttotal: 1h 25m 7s\tremaining: 1d 3h 31m 39s\n",
      "5000:\ttest: 0.9612146\tbest: 0.9612157 (4995)\ttotal: 1h 26m 44s\tremaining: 1d 3h 27m 53s\n",
      "5100:\ttest: 0.9612594\tbest: 0.9612596 (5099)\ttotal: 1h 28m 23s\tremaining: 1d 3h 24m 24s\n",
      "5200:\ttest: 0.9613547\tbest: 0.9613547 (5200)\ttotal: 1h 30m 3s\tremaining: 1d 3h 21m 35s\n",
      "5300:\ttest: 0.9613739\tbest: 0.9613743 (5296)\ttotal: 1h 31m 43s\tremaining: 1d 3h 18m 43s\n",
      "5400:\ttest: 0.9614063\tbest: 0.9614065 (5398)\ttotal: 1h 33m 22s\tremaining: 1d 3h 15m 29s\n",
      "5500:\ttest: 0.9614790\tbest: 0.9614794 (5499)\ttotal: 1h 35m 2s\tremaining: 1d 3h 12m 38s\n",
      "5600:\ttest: 0.9615265\tbest: 0.9615267 (5599)\ttotal: 1h 36m 44s\tremaining: 1d 3h 10m 21s\n",
      "5700:\ttest: 0.9615678\tbest: 0.9615678 (5700)\ttotal: 1h 38m 21s\tremaining: 1d 3h 6m 55s\n",
      "5800:\ttest: 0.9616403\tbest: 0.9616403 (5800)\ttotal: 1h 40m 1s\tremaining: 1d 3h 4m 14s\n",
      "5900:\ttest: 0.9616761\tbest: 0.9616769 (5898)\ttotal: 1h 41m 43s\tremaining: 1d 3h 2m 15s\n",
      "6000:\ttest: 0.9617466\tbest: 0.9617473 (5995)\ttotal: 1h 43m 26s\tremaining: 1d 3h 19s\n",
      "6100:\ttest: 0.9618117\tbest: 0.9618122 (6090)\ttotal: 1h 45m 8s\tremaining: 1d 2h 58m 20s\n",
      "6200:\ttest: 0.9618254\tbest: 0.9618270 (6179)\ttotal: 1h 46m 51s\tremaining: 1d 2h 56m 25s\n",
      "6300:\ttest: 0.9618379\tbest: 0.9618390 (6290)\ttotal: 1h 48m 32s\tremaining: 1d 2h 54m 2s\n",
      "6400:\ttest: 0.9618681\tbest: 0.9618681 (6400)\ttotal: 1h 50m 14s\tremaining: 1d 2h 51m 59s\n",
      "6500:\ttest: 0.9619080\tbest: 0.9619086 (6496)\ttotal: 1h 51m 56s\tremaining: 1d 2h 50m 1s\n",
      "6600:\ttest: 0.9619136\tbest: 0.9619168 (6570)\ttotal: 1h 53m 37s\tremaining: 1d 2h 47m 42s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9619167657\n",
      "bestIteration = 6570\n",
      "\n",
      "Shrink model to first 6571 iterations.\n",
      "[15:30:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.67260\ttrain-auc:0.73406\tvalid-logloss:0.67263\tvalid-auc:0.73907\n",
      "[100]\ttrain-logloss:0.22588\ttrain-auc:0.91606\tvalid-logloss:0.22733\tvalid-auc:0.91163\n",
      "[200]\ttrain-logloss:0.18287\ttrain-auc:0.94318\tvalid-logloss:0.18670\tvalid-auc:0.93618\n",
      "[300]\ttrain-logloss:0.16474\ttrain-auc:0.95404\tvalid-logloss:0.17055\tvalid-auc:0.94583\n",
      "[400]\ttrain-logloss:0.15433\ttrain-auc:0.95971\tvalid-logloss:0.16203\tvalid-auc:0.95023\n",
      "[500]\ttrain-logloss:0.14590\ttrain-auc:0.96407\tvalid-logloss:0.15543\tvalid-auc:0.95343\n",
      "[600]\ttrain-logloss:0.13929\ttrain-auc:0.96736\tvalid-logloss:0.15052\tvalid-auc:0.95582\n",
      "[700]\ttrain-logloss:0.13309\ttrain-auc:0.97043\tvalid-logloss:0.14620\tvalid-auc:0.95780\n",
      "[800]\ttrain-logloss:0.12848\ttrain-auc:0.97265\tvalid-logloss:0.14334\tvalid-auc:0.95908\n",
      "[900]\ttrain-logloss:0.12409\ttrain-auc:0.97474\tvalid-logloss:0.14061\tvalid-auc:0.96038\n",
      "[1000]\ttrain-logloss:0.12039\ttrain-auc:0.97649\tvalid-logloss:0.13857\tvalid-auc:0.96137\n",
      "[1100]\ttrain-logloss:0.11680\ttrain-auc:0.97811\tvalid-logloss:0.13667\tvalid-auc:0.96221\n",
      "[1200]\ttrain-logloss:0.11356\ttrain-auc:0.97961\tvalid-logloss:0.13507\tvalid-auc:0.96297\n",
      "[1300]\ttrain-logloss:0.10996\ttrain-auc:0.98120\tvalid-logloss:0.13339\tvalid-auc:0.96370\n",
      "[1400]\ttrain-logloss:0.10677\ttrain-auc:0.98257\tvalid-logloss:0.13192\tvalid-auc:0.96438\n",
      "[1500]\ttrain-logloss:0.10372\ttrain-auc:0.98390\tvalid-logloss:0.13059\tvalid-auc:0.96503\n",
      "[1600]\ttrain-logloss:0.10126\ttrain-auc:0.98489\tvalid-logloss:0.12951\tvalid-auc:0.96551\n",
      "[1700]\ttrain-logloss:0.09846\ttrain-auc:0.98604\tvalid-logloss:0.12841\tvalid-auc:0.96601\n",
      "[1800]\ttrain-logloss:0.09602\ttrain-auc:0.98698\tvalid-logloss:0.12750\tvalid-auc:0.96640\n",
      "[1900]\ttrain-logloss:0.09357\ttrain-auc:0.98789\tvalid-logloss:0.12657\tvalid-auc:0.96679\n",
      "[2000]\ttrain-logloss:0.09120\ttrain-auc:0.98878\tvalid-logloss:0.12579\tvalid-auc:0.96713\n",
      "[2100]\ttrain-logloss:0.08893\ttrain-auc:0.98953\tvalid-logloss:0.12519\tvalid-auc:0.96731\n",
      "[2200]\ttrain-logloss:0.08673\ttrain-auc:0.99027\tvalid-logloss:0.12460\tvalid-auc:0.96755\n",
      "[2300]\ttrain-logloss:0.08470\ttrain-auc:0.99095\tvalid-logloss:0.12403\tvalid-auc:0.96782\n",
      "[2400]\ttrain-logloss:0.08260\ttrain-auc:0.99159\tvalid-logloss:0.12336\tvalid-auc:0.96808\n",
      "[2500]\ttrain-logloss:0.08073\ttrain-auc:0.99217\tvalid-logloss:0.12287\tvalid-auc:0.96830\n",
      "[2600]\ttrain-logloss:0.07881\ttrain-auc:0.99273\tvalid-logloss:0.12233\tvalid-auc:0.96850\n",
      "[2700]\ttrain-logloss:0.07706\ttrain-auc:0.99323\tvalid-logloss:0.12183\tvalid-auc:0.96877\n",
      "[2800]\ttrain-logloss:0.07537\ttrain-auc:0.99368\tvalid-logloss:0.12140\tvalid-auc:0.96893\n",
      "[2900]\ttrain-logloss:0.07374\ttrain-auc:0.99410\tvalid-logloss:0.12097\tvalid-auc:0.96913\n",
      "[3000]\ttrain-logloss:0.07222\ttrain-auc:0.99447\tvalid-logloss:0.12068\tvalid-auc:0.96924\n",
      "[3100]\ttrain-logloss:0.07062\ttrain-auc:0.99489\tvalid-logloss:0.12032\tvalid-auc:0.96940\n",
      "[3200]\ttrain-logloss:0.06917\ttrain-auc:0.99525\tvalid-logloss:0.12006\tvalid-auc:0.96951\n",
      "[3300]\ttrain-logloss:0.06775\ttrain-auc:0.99558\tvalid-logloss:0.11976\tvalid-auc:0.96964\n",
      "[3400]\ttrain-logloss:0.06642\ttrain-auc:0.99586\tvalid-logloss:0.11948\tvalid-auc:0.96971\n",
      "[3500]\ttrain-logloss:0.06505\ttrain-auc:0.99615\tvalid-logloss:0.11917\tvalid-auc:0.96987\n",
      "[3600]\ttrain-logloss:0.06376\ttrain-auc:0.99642\tvalid-logloss:0.11889\tvalid-auc:0.96997\n",
      "[3700]\ttrain-logloss:0.06250\ttrain-auc:0.99667\tvalid-logloss:0.11882\tvalid-auc:0.96997\n",
      "[3800]\ttrain-logloss:0.06122\ttrain-auc:0.99690\tvalid-logloss:0.11862\tvalid-auc:0.97005\n",
      "[3900]\ttrain-logloss:0.06004\ttrain-auc:0.99711\tvalid-logloss:0.11841\tvalid-auc:0.97011\n",
      "[4000]\ttrain-logloss:0.05879\ttrain-auc:0.99733\tvalid-logloss:0.11818\tvalid-auc:0.97023\n",
      "[4100]\ttrain-logloss:0.05766\ttrain-auc:0.99751\tvalid-logloss:0.11815\tvalid-auc:0.97024\n",
      "[4180]\ttrain-logloss:0.05676\ttrain-auc:0.99766\tvalid-logloss:0.11807\tvalid-auc:0.97025\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.917498\ttraining's binary_logloss: 0.220355\tvalid_1's auc: 0.907174\tvalid_1's binary_logloss: 0.224175\n",
      "[400]\ttraining's auc: 0.939977\ttraining's binary_logloss: 0.188076\tvalid_1's auc: 0.929249\tvalid_1's binary_logloss: 0.19442\n",
      "[600]\ttraining's auc: 0.948785\ttraining's binary_logloss: 0.173029\tvalid_1's auc: 0.937567\tvalid_1's binary_logloss: 0.181071\n",
      "[800]\ttraining's auc: 0.954478\ttraining's binary_logloss: 0.163393\tvalid_1's auc: 0.942594\tvalid_1's binary_logloss: 0.172943\n",
      "[1000]\ttraining's auc: 0.958859\ttraining's binary_logloss: 0.155774\tvalid_1's auc: 0.946434\tvalid_1's binary_logloss: 0.166663\n",
      "[1200]\ttraining's auc: 0.962189\ttraining's binary_logloss: 0.149726\tvalid_1's auc: 0.94916\tvalid_1's binary_logloss: 0.161964\n",
      "[1400]\ttraining's auc: 0.964858\ttraining's binary_logloss: 0.144677\tvalid_1's auc: 0.95118\tvalid_1's binary_logloss: 0.158205\n",
      "[1600]\ttraining's auc: 0.967381\ttraining's binary_logloss: 0.139901\tvalid_1's auc: 0.953042\tvalid_1's binary_logloss: 0.154763\n",
      "[1800]\ttraining's auc: 0.969548\ttraining's binary_logloss: 0.135539\tvalid_1's auc: 0.954738\tvalid_1's binary_logloss: 0.15164\n",
      "[2000]\ttraining's auc: 0.971598\ttraining's binary_logloss: 0.131514\tvalid_1's auc: 0.956139\tvalid_1's binary_logloss: 0.148967\n",
      "[2200]\ttraining's auc: 0.973322\ttraining's binary_logloss: 0.128034\tvalid_1's auc: 0.957262\tvalid_1's binary_logloss: 0.146803\n",
      "[2400]\ttraining's auc: 0.974925\ttraining's binary_logloss: 0.124658\tvalid_1's auc: 0.958278\tvalid_1's binary_logloss: 0.144826\n",
      "[2600]\ttraining's auc: 0.976358\ttraining's binary_logloss: 0.121688\tvalid_1's auc: 0.959197\tvalid_1's binary_logloss: 0.143083\n",
      "[2800]\ttraining's auc: 0.977855\ttraining's binary_logloss: 0.118556\tvalid_1's auc: 0.960075\tvalid_1's binary_logloss: 0.141359\n",
      "[3000]\ttraining's auc: 0.979063\ttraining's binary_logloss: 0.115919\tvalid_1's auc: 0.960769\tvalid_1's binary_logloss: 0.139954\n",
      "[3200]\ttraining's auc: 0.980325\ttraining's binary_logloss: 0.113154\tvalid_1's auc: 0.961507\tvalid_1's binary_logloss: 0.138496\n",
      "[3400]\ttraining's auc: 0.981416\ttraining's binary_logloss: 0.110645\tvalid_1's auc: 0.962187\tvalid_1's binary_logloss: 0.137114\n",
      "[3600]\ttraining's auc: 0.982475\ttraining's binary_logloss: 0.108127\tvalid_1's auc: 0.962879\tvalid_1's binary_logloss: 0.135774\n",
      "[3800]\ttraining's auc: 0.983554\ttraining's binary_logloss: 0.105602\tvalid_1's auc: 0.963508\tvalid_1's binary_logloss: 0.134537\n",
      "[4000]\ttraining's auc: 0.984515\ttraining's binary_logloss: 0.103305\tvalid_1's auc: 0.964014\tvalid_1's binary_logloss: 0.13353\n",
      "[4200]\ttraining's auc: 0.985441\ttraining's binary_logloss: 0.101029\tvalid_1's auc: 0.964481\tvalid_1's binary_logloss: 0.132527\n",
      "[4400]\ttraining's auc: 0.986197\ttraining's binary_logloss: 0.0989725\tvalid_1's auc: 0.964926\tvalid_1's binary_logloss: 0.13153\n",
      "[4600]\ttraining's auc: 0.986992\ttraining's binary_logloss: 0.0970023\tvalid_1's auc: 0.96532\tvalid_1's binary_logloss: 0.130713\n",
      "[4800]\ttraining's auc: 0.987685\ttraining's binary_logloss: 0.0951884\tvalid_1's auc: 0.965639\tvalid_1's binary_logloss: 0.130013\n",
      "[5000]\ttraining's auc: 0.98842\ttraining's binary_logloss: 0.0931951\tvalid_1's auc: 0.966036\tvalid_1's binary_logloss: 0.129203\n",
      "[5200]\ttraining's auc: 0.98909\ttraining's binary_logloss: 0.0913094\tvalid_1's auc: 0.966376\tvalid_1's binary_logloss: 0.128475\n",
      "[5400]\ttraining's auc: 0.989705\ttraining's binary_logloss: 0.0895254\tvalid_1's auc: 0.966732\tvalid_1's binary_logloss: 0.127705\n",
      "[5600]\ttraining's auc: 0.99029\ttraining's binary_logloss: 0.0877917\tvalid_1's auc: 0.967069\tvalid_1's binary_logloss: 0.126967\n",
      "[5800]\ttraining's auc: 0.990865\ttraining's binary_logloss: 0.086101\tvalid_1's auc: 0.967353\tvalid_1's binary_logloss: 0.126372\n",
      "[6000]\ttraining's auc: 0.991412\ttraining's binary_logloss: 0.0844385\tvalid_1's auc: 0.967639\tvalid_1's binary_logloss: 0.125769\n",
      "[6200]\ttraining's auc: 0.991912\ttraining's binary_logloss: 0.0828736\tvalid_1's auc: 0.967865\tvalid_1's binary_logloss: 0.125221\n",
      "[6400]\ttraining's auc: 0.992384\ttraining's binary_logloss: 0.0812276\tvalid_1's auc: 0.968102\tvalid_1's binary_logloss: 0.124632\n",
      "[6600]\ttraining's auc: 0.992832\ttraining's binary_logloss: 0.0796949\tvalid_1's auc: 0.968322\tvalid_1's binary_logloss: 0.124082\n",
      "[6800]\ttraining's auc: 0.993268\ttraining's binary_logloss: 0.0781556\tvalid_1's auc: 0.968589\tvalid_1's binary_logloss: 0.123491\n",
      "[7000]\ttraining's auc: 0.993645\ttraining's binary_logloss: 0.0768006\tvalid_1's auc: 0.968761\tvalid_1's binary_logloss: 0.123098\n",
      "[7200]\ttraining's auc: 0.994002\ttraining's binary_logloss: 0.0754423\tvalid_1's auc: 0.968912\tvalid_1's binary_logloss: 0.122691\n",
      "[7400]\ttraining's auc: 0.99434\ttraining's binary_logloss: 0.0741657\tvalid_1's auc: 0.968999\tvalid_1's binary_logloss: 0.122401\n",
      "[7600]\ttraining's auc: 0.994717\ttraining's binary_logloss: 0.0726689\tvalid_1's auc: 0.96923\tvalid_1's binary_logloss: 0.12186\n",
      "[7800]\ttraining's auc: 0.995002\ttraining's binary_logloss: 0.0714555\tvalid_1's auc: 0.969392\tvalid_1's binary_logloss: 0.121507\n",
      "[8000]\ttraining's auc: 0.995322\ttraining's binary_logloss: 0.0702127\tvalid_1's auc: 0.96947\tvalid_1's binary_logloss: 0.121263\n",
      "[8200]\ttraining's auc: 0.995586\ttraining's binary_logloss: 0.0690326\tvalid_1's auc: 0.969568\tvalid_1's binary_logloss: 0.121\n",
      "[8400]\ttraining's auc: 0.995859\ttraining's binary_logloss: 0.0677711\tvalid_1's auc: 0.96975\tvalid_1's binary_logloss: 0.120576\n",
      "[8600]\ttraining's auc: 0.996097\ttraining's binary_logloss: 0.066662\tvalid_1's auc: 0.969858\tvalid_1's binary_logloss: 0.120286\n",
      "[8800]\ttraining's auc: 0.996337\ttraining's binary_logloss: 0.0655162\tvalid_1's auc: 0.969959\tvalid_1's binary_logloss: 0.119973\n",
      "[9000]\ttraining's auc: 0.99656\ttraining's binary_logloss: 0.064434\tvalid_1's auc: 0.970035\tvalid_1's binary_logloss: 0.119764\n",
      "[9200]\ttraining's auc: 0.996767\ttraining's binary_logloss: 0.0633765\tvalid_1's auc: 0.970164\tvalid_1's binary_logloss: 0.11951\n",
      "[9400]\ttraining's auc: 0.996968\ttraining's binary_logloss: 0.0622913\tvalid_1's auc: 0.970275\tvalid_1's binary_logloss: 0.119222\n",
      "[9600]\ttraining's auc: 0.997148\ttraining's binary_logloss: 0.0612784\tvalid_1's auc: 0.970357\tvalid_1's binary_logloss: 0.118969\n",
      "[9800]\ttraining's auc: 0.997322\ttraining's binary_logloss: 0.0602912\tvalid_1's auc: 0.970443\tvalid_1's binary_logloss: 0.118768\n",
      "[10000]\ttraining's auc: 0.997484\ttraining's binary_logloss: 0.0593094\tvalid_1's auc: 0.970469\tvalid_1's binary_logloss: 0.118632\n",
      "[10200]\ttraining's auc: 0.997649\ttraining's binary_logloss: 0.0583597\tvalid_1's auc: 0.970576\tvalid_1's binary_logloss: 0.118412\n",
      "[10400]\ttraining's auc: 0.997804\ttraining's binary_logloss: 0.0573718\tvalid_1's auc: 0.970647\tvalid_1's binary_logloss: 0.118158\n",
      "[10600]\ttraining's auc: 0.997915\ttraining's binary_logloss: 0.0565662\tvalid_1's auc: 0.970679\tvalid_1's binary_logloss: 0.118048\n",
      "[10800]\ttraining's auc: 0.998052\ttraining's binary_logloss: 0.055627\tvalid_1's auc: 0.970781\tvalid_1's binary_logloss: 0.117818\n",
      "[11000]\ttraining's auc: 0.998176\ttraining's binary_logloss: 0.0547464\tvalid_1's auc: 0.970857\tvalid_1's binary_logloss: 0.117646\n",
      "[11200]\ttraining's auc: 0.99828\ttraining's binary_logloss: 0.0539422\tvalid_1's auc: 0.970941\tvalid_1's binary_logloss: 0.117478\n",
      "[11400]\ttraining's auc: 0.998383\ttraining's binary_logloss: 0.0531239\tvalid_1's auc: 0.970975\tvalid_1's binary_logloss: 0.117342\n",
      "[11600]\ttraining's auc: 0.998488\ttraining's binary_logloss: 0.0522858\tvalid_1's auc: 0.971034\tvalid_1's binary_logloss: 0.117189\n",
      "[11800]\ttraining's auc: 0.998578\ttraining's binary_logloss: 0.0515154\tvalid_1's auc: 0.97105\tvalid_1's binary_logloss: 0.117139\n",
      "[12000]\ttraining's auc: 0.998664\ttraining's binary_logloss: 0.0507599\tvalid_1's auc: 0.971103\tvalid_1's binary_logloss: 0.116986\n",
      "[12200]\ttraining's auc: 0.998748\ttraining's binary_logloss: 0.0500153\tvalid_1's auc: 0.971161\tvalid_1's binary_logloss: 0.116865\n",
      "[12400]\ttraining's auc: 0.998832\ttraining's binary_logloss: 0.0492773\tvalid_1's auc: 0.971187\tvalid_1's binary_logloss: 0.116806\n",
      "[12600]\ttraining's auc: 0.998906\ttraining's binary_logloss: 0.0485664\tvalid_1's auc: 0.971204\tvalid_1's binary_logloss: 0.11674\n",
      "[12800]\ttraining's auc: 0.998972\ttraining's binary_logloss: 0.0478518\tvalid_1's auc: 0.971258\tvalid_1's binary_logloss: 0.116646\n",
      "[13000]\ttraining's auc: 0.99904\ttraining's binary_logloss: 0.0471787\tvalid_1's auc: 0.971308\tvalid_1's binary_logloss: 0.116516\n",
      "[13200]\ttraining's auc: 0.999102\ttraining's binary_logloss: 0.0465024\tvalid_1's auc: 0.971319\tvalid_1's binary_logloss: 0.11645\n",
      "[13400]\ttraining's auc: 0.99916\ttraining's binary_logloss: 0.0458272\tvalid_1's auc: 0.971364\tvalid_1's binary_logloss: 0.116362\n",
      "[13600]\ttraining's auc: 0.99921\ttraining's binary_logloss: 0.0451886\tvalid_1's auc: 0.971361\tvalid_1's binary_logloss: 0.11635\n",
      "[13800]\ttraining's auc: 0.999258\ttraining's binary_logloss: 0.0445822\tvalid_1's auc: 0.971342\tvalid_1's binary_logloss: 0.116363\n",
      "[14000]\ttraining's auc: 0.999302\ttraining's binary_logloss: 0.043963\tvalid_1's auc: 0.97136\tvalid_1's binary_logloss: 0.116322\n",
      "[14200]\ttraining's auc: 0.999349\ttraining's binary_logloss: 0.043356\tvalid_1's auc: 0.971391\tvalid_1's binary_logloss: 0.11626\n",
      "[14400]\ttraining's auc: 0.999386\ttraining's binary_logloss: 0.0427776\tvalid_1's auc: 0.971393\tvalid_1's binary_logloss: 0.11626\n",
      "[14600]\ttraining's auc: 0.999429\ttraining's binary_logloss: 0.0421514\tvalid_1's auc: 0.971436\tvalid_1's binary_logloss: 0.116227\n",
      "[14800]\ttraining's auc: 0.999463\ttraining's binary_logloss: 0.0416151\tvalid_1's auc: 0.971444\tvalid_1's binary_logloss: 0.116193\n",
      "[15000]\ttraining's auc: 0.999497\ttraining's binary_logloss: 0.0410432\tvalid_1's auc: 0.971456\tvalid_1's binary_logloss: 0.11614\n",
      "[15200]\ttraining's auc: 0.999525\ttraining's binary_logloss: 0.0405101\tvalid_1's auc: 0.971469\tvalid_1's binary_logloss: 0.116113\n",
      "[15400]\ttraining's auc: 0.999553\ttraining's binary_logloss: 0.0400179\tvalid_1's auc: 0.971464\tvalid_1's binary_logloss: 0.116111\n",
      "[15600]\ttraining's auc: 0.99958\ttraining's binary_logloss: 0.0395292\tvalid_1's auc: 0.971483\tvalid_1's binary_logloss: 0.116105\n",
      "[15800]\ttraining's auc: 0.999607\ttraining's binary_logloss: 0.0390051\tvalid_1's auc: 0.971496\tvalid_1's binary_logloss: 0.11607\n",
      "[16000]\ttraining's auc: 0.999632\ttraining's binary_logloss: 0.0385029\tvalid_1's auc: 0.97149\tvalid_1's binary_logloss: 0.116103\n",
      "[16200]\ttraining's auc: 0.999654\ttraining's binary_logloss: 0.0380096\tvalid_1's auc: 0.971504\tvalid_1's binary_logloss: 0.116073\n",
      "[16400]\ttraining's auc: 0.999675\ttraining's binary_logloss: 0.0375548\tvalid_1's auc: 0.971504\tvalid_1's binary_logloss: 0.116092\n",
      "[16600]\ttraining's auc: 0.999695\ttraining's binary_logloss: 0.0370974\tvalid_1's auc: 0.971525\tvalid_1's binary_logloss: 0.116077\n",
      "[16800]\ttraining's auc: 0.999713\ttraining's binary_logloss: 0.0366796\tvalid_1's auc: 0.971524\tvalid_1's binary_logloss: 0.11607\n",
      "[17000]\ttraining's auc: 0.999731\ttraining's binary_logloss: 0.0362364\tvalid_1's auc: 0.971548\tvalid_1's binary_logloss: 0.116052\n",
      "[17200]\ttraining's auc: 0.999748\ttraining's binary_logloss: 0.0358162\tvalid_1's auc: 0.971558\tvalid_1's binary_logloss: 0.116061\n",
      "[17400]\ttraining's auc: 0.999766\ttraining's binary_logloss: 0.0353862\tvalid_1's auc: 0.971597\tvalid_1's binary_logloss: 0.116024\n",
      "[17600]\ttraining's auc: 0.999781\ttraining's binary_logloss: 0.0349616\tvalid_1's auc: 0.971597\tvalid_1's binary_logloss: 0.11606\n",
      "[17800]\ttraining's auc: 0.999793\ttraining's binary_logloss: 0.0345665\tvalid_1's auc: 0.971611\tvalid_1's binary_logloss: 0.116044\n",
      "Early stopping, best iteration is:\n",
      "[17400]\ttraining's auc: 0.999766\ttraining's binary_logloss: 0.0353862\tvalid_1's auc: 0.971597\tvalid_1's binary_logloss: 0.116024\n",
      "0:\ttest: 0.7143267\tbest: 0.7143267 (0)\ttotal: 981ms\tremaining: 1d 3h 15m 12s\n",
      "100:\ttest: 0.8555422\tbest: 0.8557537 (99)\ttotal: 1m 43s\tremaining: 1d 4h 25m 52s\n",
      "200:\ttest: 0.8756236\tbest: 0.8756236 (200)\ttotal: 3m 26s\tremaining: 1d 4h 26m 55s\n",
      "300:\ttest: 0.8963588\tbest: 0.8963588 (300)\ttotal: 5m 9s\tremaining: 1d 4h 27m 29s\n",
      "400:\ttest: 0.9111428\tbest: 0.9111428 (400)\ttotal: 6m 52s\tremaining: 1d 4h 26m 42s\n",
      "500:\ttest: 0.9192252\tbest: 0.9192252 (500)\ttotal: 8m 35s\tremaining: 1d 4h 26m 38s\n",
      "600:\ttest: 0.9262256\tbest: 0.9262256 (600)\ttotal: 10m 18s\tremaining: 1d 4h 24m 28s\n",
      "700:\ttest: 0.9311121\tbest: 0.9311121 (700)\ttotal: 12m 2s\tremaining: 1d 4h 26m 6s\n",
      "800:\ttest: 0.9350489\tbest: 0.9350489 (800)\ttotal: 13m 45s\tremaining: 1d 4h 23m 59s\n",
      "900:\ttest: 0.9386483\tbest: 0.9386483 (900)\ttotal: 15m 28s\tremaining: 1d 4h 21m 37s\n",
      "1000:\ttest: 0.9411127\tbest: 0.9411127 (1000)\ttotal: 17m 11s\tremaining: 1d 4h 19m 31s\n",
      "1100:\ttest: 0.9434244\tbest: 0.9434244 (1100)\ttotal: 18m 53s\tremaining: 1d 4h 17m 39s\n",
      "1200:\ttest: 0.9450705\tbest: 0.9450705 (1200)\ttotal: 20m 36s\tremaining: 1d 4h 15m 28s\n",
      "1300:\ttest: 0.9466738\tbest: 0.9466738 (1300)\ttotal: 22m 19s\tremaining: 1d 4h 13m 12s\n",
      "1400:\ttest: 0.9478406\tbest: 0.9478406 (1400)\ttotal: 24m 1s\tremaining: 1d 4h 11m 3s\n",
      "1500:\ttest: 0.9489120\tbest: 0.9489120 (1500)\ttotal: 25m 44s\tremaining: 1d 4h 8m 54s\n",
      "1600:\ttest: 0.9499467\tbest: 0.9499467 (1600)\ttotal: 27m 26s\tremaining: 1d 4h 6m 41s\n",
      "1700:\ttest: 0.9506787\tbest: 0.9506787 (1700)\ttotal: 29m 8s\tremaining: 1d 4h 4m 27s\n",
      "1800:\ttest: 0.9515731\tbest: 0.9515731 (1800)\ttotal: 30m 51s\tremaining: 1d 4h 2m 23s\n",
      "1900:\ttest: 0.9523523\tbest: 0.9523526 (1899)\ttotal: 32m 33s\tremaining: 1d 4h 29s\n",
      "2000:\ttest: 0.9530092\tbest: 0.9530092 (2000)\ttotal: 34m 16s\tremaining: 1d 3h 58m 38s\n",
      "2100:\ttest: 0.9534114\tbest: 0.9534114 (2100)\ttotal: 35m 58s\tremaining: 1d 3h 56m 23s\n",
      "2200:\ttest: 0.9541206\tbest: 0.9541206 (2200)\ttotal: 37m 41s\tremaining: 1d 3h 54m 30s\n",
      "2300:\ttest: 0.9548319\tbest: 0.9548319 (2300)\ttotal: 39m 23s\tremaining: 1d 3h 52m 50s\n",
      "2400:\ttest: 0.9551808\tbest: 0.9551829 (2397)\ttotal: 41m 5s\tremaining: 1d 3h 50m 35s\n",
      "2500:\ttest: 0.9554813\tbest: 0.9554813 (2500)\ttotal: 42m 46s\tremaining: 1d 3h 47m 22s\n",
      "2600:\ttest: 0.9557746\tbest: 0.9557746 (2600)\ttotal: 44m 28s\tremaining: 1d 3h 45m 15s\n",
      "2700:\ttest: 0.9560302\tbest: 0.9560313 (2697)\ttotal: 46m 10s\tremaining: 1d 3h 43m 20s\n",
      "2800:\ttest: 0.9562510\tbest: 0.9562510 (2800)\ttotal: 47m 52s\tremaining: 1d 3h 41m 15s\n",
      "2900:\ttest: 0.9564314\tbest: 0.9564327 (2898)\ttotal: 49m 34s\tremaining: 1d 3h 39m 11s\n",
      "3000:\ttest: 0.9566656\tbest: 0.9566676 (2998)\ttotal: 51m 16s\tremaining: 1d 3h 37m 24s\n",
      "3100:\ttest: 0.9568310\tbest: 0.9568328 (3096)\ttotal: 52m 58s\tremaining: 1d 3h 35m 9s\n",
      "3200:\ttest: 0.9569566\tbest: 0.9569591 (3192)\ttotal: 54m 39s\tremaining: 1d 3h 33m 5s\n",
      "3300:\ttest: 0.9570846\tbest: 0.9570846 (3300)\ttotal: 56m 21s\tremaining: 1d 3h 30m 58s\n",
      "3400:\ttest: 0.9571301\tbest: 0.9571301 (3400)\ttotal: 58m 3s\tremaining: 1d 3h 29m 1s\n",
      "3500:\ttest: 0.9571934\tbest: 0.9571974 (3468)\ttotal: 59m 45s\tremaining: 1d 3h 26m 55s\n",
      "3600:\ttest: 0.9573853\tbest: 0.9573883 (3581)\ttotal: 1h 1m 27s\tremaining: 1d 3h 25m 3s\n",
      "3700:\ttest: 0.9574816\tbest: 0.9574845 (3693)\ttotal: 1h 3m 8s\tremaining: 1d 3h 22m 48s\n",
      "3800:\ttest: 0.9575159\tbest: 0.9575215 (3753)\ttotal: 1h 4m 49s\tremaining: 1d 3h 20m 26s\n",
      "3900:\ttest: 0.9575757\tbest: 0.9575928 (3855)\ttotal: 1h 6m 29s\tremaining: 1d 3h 18m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.957592835\n",
      "bestIteration = 3855\n",
      "\n",
      "Shrink model to first 3856 iterations.\n",
      "[16:50:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.67265\ttrain-auc:0.71769\tvalid-logloss:0.67269\tvalid-auc:0.71258\n",
      "[100]\ttrain-logloss:0.22573\ttrain-auc:0.91655\tvalid-logloss:0.22986\tvalid-auc:0.90533\n",
      "[200]\ttrain-logloss:0.18225\ttrain-auc:0.94381\tvalid-logloss:0.18974\tvalid-auc:0.93204\n",
      "[300]\ttrain-logloss:0.16467\ttrain-auc:0.95392\tvalid-logloss:0.17429\tvalid-auc:0.94173\n",
      "[400]\ttrain-logloss:0.15384\ttrain-auc:0.95978\tvalid-logloss:0.16538\tvalid-auc:0.94692\n",
      "[500]\ttrain-logloss:0.14541\ttrain-auc:0.96408\tvalid-logloss:0.15878\tvalid-auc:0.95061\n",
      "[600]\ttrain-logloss:0.13857\ttrain-auc:0.96745\tvalid-logloss:0.15389\tvalid-auc:0.95318\n",
      "[700]\ttrain-logloss:0.13310\ttrain-auc:0.97007\tvalid-logloss:0.15019\tvalid-auc:0.95501\n",
      "[800]\ttrain-logloss:0.12843\ttrain-auc:0.97233\tvalid-logloss:0.14718\tvalid-auc:0.95650\n",
      "[900]\ttrain-logloss:0.12424\ttrain-auc:0.97429\tvalid-logloss:0.14467\tvalid-auc:0.95771\n",
      "[1000]\ttrain-logloss:0.12055\ttrain-auc:0.97603\tvalid-logloss:0.14263\tvalid-auc:0.95874\n",
      "[1100]\ttrain-logloss:0.11658\ttrain-auc:0.97790\tvalid-logloss:0.14043\tvalid-auc:0.95988\n",
      "[1200]\ttrain-logloss:0.11286\ttrain-auc:0.97961\tvalid-logloss:0.13845\tvalid-auc:0.96092\n",
      "[1300]\ttrain-logloss:0.10975\ttrain-auc:0.98097\tvalid-logloss:0.13691\tvalid-auc:0.96170\n",
      "[1400]\ttrain-logloss:0.10657\ttrain-auc:0.98234\tvalid-logloss:0.13521\tvalid-auc:0.96255\n",
      "[1500]\ttrain-logloss:0.10369\ttrain-auc:0.98363\tvalid-logloss:0.13391\tvalid-auc:0.96324\n",
      "[1600]\ttrain-logloss:0.10094\ttrain-auc:0.98473\tvalid-logloss:0.13271\tvalid-auc:0.96379\n",
      "[1700]\ttrain-logloss:0.09836\ttrain-auc:0.98575\tvalid-logloss:0.13165\tvalid-auc:0.96428\n",
      "[1800]\ttrain-logloss:0.09584\ttrain-auc:0.98674\tvalid-logloss:0.13069\tvalid-auc:0.96475\n",
      "[1900]\ttrain-logloss:0.09335\ttrain-auc:0.98768\tvalid-logloss:0.12969\tvalid-auc:0.96523\n",
      "[2000]\ttrain-logloss:0.09105\ttrain-auc:0.98853\tvalid-logloss:0.12882\tvalid-auc:0.96567\n",
      "[2100]\ttrain-logloss:0.08893\ttrain-auc:0.98929\tvalid-logloss:0.12806\tvalid-auc:0.96601\n",
      "[2200]\ttrain-logloss:0.08685\ttrain-auc:0.99002\tvalid-logloss:0.12747\tvalid-auc:0.96629\n",
      "[2300]\ttrain-logloss:0.08482\ttrain-auc:0.99067\tvalid-logloss:0.12670\tvalid-auc:0.96667\n",
      "[2400]\ttrain-logloss:0.08275\ttrain-auc:0.99132\tvalid-logloss:0.12596\tvalid-auc:0.96699\n",
      "[2500]\ttrain-logloss:0.08093\ttrain-auc:0.99190\tvalid-logloss:0.12547\tvalid-auc:0.96718\n",
      "[2600]\ttrain-logloss:0.07912\ttrain-auc:0.99247\tvalid-logloss:0.12504\tvalid-auc:0.96738\n",
      "[2700]\ttrain-logloss:0.07752\ttrain-auc:0.99294\tvalid-logloss:0.12469\tvalid-auc:0.96751\n",
      "[2800]\ttrain-logloss:0.07581\ttrain-auc:0.99342\tvalid-logloss:0.12427\tvalid-auc:0.96771\n",
      "[2900]\ttrain-logloss:0.07424\ttrain-auc:0.99384\tvalid-logloss:0.12387\tvalid-auc:0.96786\n",
      "[3000]\ttrain-logloss:0.07264\ttrain-auc:0.99428\tvalid-logloss:0.12352\tvalid-auc:0.96796\n",
      "[3100]\ttrain-logloss:0.07100\ttrain-auc:0.99470\tvalid-logloss:0.12307\tvalid-auc:0.96819\n",
      "[3200]\ttrain-logloss:0.06946\ttrain-auc:0.99507\tvalid-logloss:0.12262\tvalid-auc:0.96842\n",
      "[3300]\ttrain-logloss:0.06802\ttrain-auc:0.99541\tvalid-logloss:0.12235\tvalid-auc:0.96852\n",
      "[3400]\ttrain-logloss:0.06656\ttrain-auc:0.99575\tvalid-logloss:0.12193\tvalid-auc:0.96867\n",
      "[3500]\ttrain-logloss:0.06510\ttrain-auc:0.99608\tvalid-logloss:0.12160\tvalid-auc:0.96881\n",
      "[3600]\ttrain-logloss:0.06378\ttrain-auc:0.99635\tvalid-logloss:0.12132\tvalid-auc:0.96892\n",
      "[3700]\ttrain-logloss:0.06246\ttrain-auc:0.99662\tvalid-logloss:0.12114\tvalid-auc:0.96899\n",
      "[3800]\ttrain-logloss:0.06124\ttrain-auc:0.99685\tvalid-logloss:0.12095\tvalid-auc:0.96906\n",
      "[3900]\ttrain-logloss:0.06000\ttrain-auc:0.99707\tvalid-logloss:0.12072\tvalid-auc:0.96915\n",
      "[4000]\ttrain-logloss:0.05885\ttrain-auc:0.99728\tvalid-logloss:0.12054\tvalid-auc:0.96925\n",
      "[4100]\ttrain-logloss:0.05771\ttrain-auc:0.99747\tvalid-logloss:0.12034\tvalid-auc:0.96934\n",
      "[4200]\ttrain-logloss:0.05655\ttrain-auc:0.99765\tvalid-logloss:0.12014\tvalid-auc:0.96941\n",
      "[4300]\ttrain-logloss:0.05541\ttrain-auc:0.99783\tvalid-logloss:0.11992\tvalid-auc:0.96951\n",
      "[4400]\ttrain-logloss:0.05433\ttrain-auc:0.99799\tvalid-logloss:0.11975\tvalid-auc:0.96960\n",
      "[4500]\ttrain-logloss:0.05325\ttrain-auc:0.99814\tvalid-logloss:0.11960\tvalid-auc:0.96966\n",
      "[4600]\ttrain-logloss:0.05230\ttrain-auc:0.99826\tvalid-logloss:0.11954\tvalid-auc:0.96970\n",
      "[4700]\ttrain-logloss:0.05131\ttrain-auc:0.99839\tvalid-logloss:0.11953\tvalid-auc:0.96972\n",
      "[4780]\ttrain-logloss:0.05054\ttrain-auc:0.99849\tvalid-logloss:0.11949\tvalid-auc:0.96972\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.917793\ttraining's binary_logloss: 0.220439\tvalid_1's auc: 0.914622\tvalid_1's binary_logloss: 0.22291\n",
      "[400]\ttraining's auc: 0.939844\ttraining's binary_logloss: 0.188521\tvalid_1's auc: 0.93605\tvalid_1's binary_logloss: 0.191819\n",
      "[600]\ttraining's auc: 0.947903\ttraining's binary_logloss: 0.174107\tvalid_1's auc: 0.942671\tvalid_1's binary_logloss: 0.178739\n",
      "[800]\ttraining's auc: 0.953717\ttraining's binary_logloss: 0.164811\tvalid_1's auc: 0.947337\tvalid_1's binary_logloss: 0.170608\n",
      "[1000]\ttraining's auc: 0.957977\ttraining's binary_logloss: 0.157454\tvalid_1's auc: 0.950733\tvalid_1's binary_logloss: 0.164311\n",
      "[1200]\ttraining's auc: 0.961517\ttraining's binary_logloss: 0.151077\tvalid_1's auc: 0.953623\tvalid_1's binary_logloss: 0.158928\n",
      "[1400]\ttraining's auc: 0.964585\ttraining's binary_logloss: 0.14537\tvalid_1's auc: 0.955847\tvalid_1's binary_logloss: 0.154411\n",
      "[1600]\ttraining's auc: 0.966821\ttraining's binary_logloss: 0.140928\tvalid_1's auc: 0.957418\tvalid_1's binary_logloss: 0.151061\n",
      "[1800]\ttraining's auc: 0.968952\ttraining's binary_logloss: 0.136804\tvalid_1's auc: 0.958729\tvalid_1's binary_logloss: 0.148234\n",
      "[2000]\ttraining's auc: 0.971006\ttraining's binary_logloss: 0.132726\tvalid_1's auc: 0.960171\tvalid_1's binary_logloss: 0.145363\n",
      "[2200]\ttraining's auc: 0.972674\ttraining's binary_logloss: 0.129383\tvalid_1's auc: 0.961122\tvalid_1's binary_logloss: 0.143252\n",
      "[2400]\ttraining's auc: 0.97419\ttraining's binary_logloss: 0.126244\tvalid_1's auc: 0.962024\tvalid_1's binary_logloss: 0.141221\n",
      "[2600]\ttraining's auc: 0.975609\ttraining's binary_logloss: 0.123293\tvalid_1's auc: 0.962908\tvalid_1's binary_logloss: 0.139421\n",
      "[2800]\ttraining's auc: 0.976989\ttraining's binary_logloss: 0.120446\tvalid_1's auc: 0.963644\tvalid_1's binary_logloss: 0.137815\n",
      "[3000]\ttraining's auc: 0.978421\ttraining's binary_logloss: 0.117367\tvalid_1's auc: 0.96444\tvalid_1's binary_logloss: 0.136067\n",
      "[3200]\ttraining's auc: 0.979649\ttraining's binary_logloss: 0.11467\tvalid_1's auc: 0.965133\tvalid_1's binary_logloss: 0.134592\n",
      "[3400]\ttraining's auc: 0.980897\ttraining's binary_logloss: 0.111902\tvalid_1's auc: 0.965849\tvalid_1's binary_logloss: 0.133101\n",
      "[3600]\ttraining's auc: 0.982005\ttraining's binary_logloss: 0.109463\tvalid_1's auc: 0.966377\tvalid_1's binary_logloss: 0.131942\n",
      "[3800]\ttraining's auc: 0.983037\ttraining's binary_logloss: 0.10708\tvalid_1's auc: 0.96689\tvalid_1's binary_logloss: 0.130778\n",
      "[4000]\ttraining's auc: 0.984059\ttraining's binary_logloss: 0.104634\tvalid_1's auc: 0.967371\tvalid_1's binary_logloss: 0.129623\n",
      "[4200]\ttraining's auc: 0.985069\ttraining's binary_logloss: 0.102283\tvalid_1's auc: 0.967866\tvalid_1's binary_logloss: 0.12849\n",
      "[4400]\ttraining's auc: 0.985889\ttraining's binary_logloss: 0.100211\tvalid_1's auc: 0.96821\tvalid_1's binary_logloss: 0.127668\n",
      "[4600]\ttraining's auc: 0.986651\ttraining's binary_logloss: 0.0981648\tvalid_1's auc: 0.968558\tvalid_1's binary_logloss: 0.126772\n",
      "[4800]\ttraining's auc: 0.987469\ttraining's binary_logloss: 0.0959571\tvalid_1's auc: 0.96901\tvalid_1's binary_logloss: 0.1257\n",
      "[5000]\ttraining's auc: 0.988104\ttraining's binary_logloss: 0.0941385\tvalid_1's auc: 0.969232\tvalid_1's binary_logloss: 0.125039\n",
      "[5200]\ttraining's auc: 0.988836\ttraining's binary_logloss: 0.0921115\tvalid_1's auc: 0.969593\tvalid_1's binary_logloss: 0.124136\n",
      "[5400]\ttraining's auc: 0.989505\ttraining's binary_logloss: 0.090238\tvalid_1's auc: 0.969926\tvalid_1's binary_logloss: 0.123401\n",
      "[5600]\ttraining's auc: 0.990108\ttraining's binary_logloss: 0.0884911\tvalid_1's auc: 0.970207\tvalid_1's binary_logloss: 0.122742\n",
      "[5800]\ttraining's auc: 0.990674\ttraining's binary_logloss: 0.0867475\tvalid_1's auc: 0.970476\tvalid_1's binary_logloss: 0.12206\n",
      "[6000]\ttraining's auc: 0.991212\ttraining's binary_logloss: 0.0850914\tvalid_1's auc: 0.970687\tvalid_1's binary_logloss: 0.121477\n",
      "[6200]\ttraining's auc: 0.991738\ttraining's binary_logloss: 0.0834357\tvalid_1's auc: 0.97096\tvalid_1's binary_logloss: 0.120825\n",
      "[6400]\ttraining's auc: 0.992239\ttraining's binary_logloss: 0.0817608\tvalid_1's auc: 0.971149\tvalid_1's binary_logloss: 0.12025\n",
      "[6600]\ttraining's auc: 0.992692\ttraining's binary_logloss: 0.08017\tvalid_1's auc: 0.971326\tvalid_1's binary_logloss: 0.119707\n",
      "[6800]\ttraining's auc: 0.993113\ttraining's binary_logloss: 0.0787007\tvalid_1's auc: 0.97146\tvalid_1's binary_logloss: 0.119263\n",
      "[7000]\ttraining's auc: 0.993525\ttraining's binary_logloss: 0.0772604\tvalid_1's auc: 0.971609\tvalid_1's binary_logloss: 0.118789\n",
      "[7200]\ttraining's auc: 0.993905\ttraining's binary_logloss: 0.07583\tvalid_1's auc: 0.971765\tvalid_1's binary_logloss: 0.118352\n",
      "[7400]\ttraining's auc: 0.994244\ttraining's binary_logloss: 0.0745077\tvalid_1's auc: 0.971907\tvalid_1's binary_logloss: 0.117953\n",
      "[7600]\ttraining's auc: 0.994555\ttraining's binary_logloss: 0.0732543\tvalid_1's auc: 0.971975\tvalid_1's binary_logloss: 0.117615\n",
      "[7800]\ttraining's auc: 0.99489\ttraining's binary_logloss: 0.0719118\tvalid_1's auc: 0.972147\tvalid_1's binary_logloss: 0.117179\n",
      "[8000]\ttraining's auc: 0.995198\ttraining's binary_logloss: 0.0705857\tvalid_1's auc: 0.972236\tvalid_1's binary_logloss: 0.11684\n",
      "[8200]\ttraining's auc: 0.995468\ttraining's binary_logloss: 0.0693417\tvalid_1's auc: 0.972332\tvalid_1's binary_logloss: 0.116516\n",
      "[8400]\ttraining's auc: 0.99574\ttraining's binary_logloss: 0.0681347\tvalid_1's auc: 0.972438\tvalid_1's binary_logloss: 0.116218\n",
      "[8600]\ttraining's auc: 0.996009\ttraining's binary_logloss: 0.0669561\tvalid_1's auc: 0.972549\tvalid_1's binary_logloss: 0.115923\n",
      "[8800]\ttraining's auc: 0.996235\ttraining's binary_logloss: 0.0658711\tvalid_1's auc: 0.972632\tvalid_1's binary_logloss: 0.115669\n",
      "[9000]\ttraining's auc: 0.99645\ttraining's binary_logloss: 0.0647681\tvalid_1's auc: 0.972738\tvalid_1's binary_logloss: 0.115332\n",
      "[9200]\ttraining's auc: 0.996664\ttraining's binary_logloss: 0.0636616\tvalid_1's auc: 0.972876\tvalid_1's binary_logloss: 0.114983\n",
      "[9400]\ttraining's auc: 0.996866\ttraining's binary_logloss: 0.0626023\tvalid_1's auc: 0.973019\tvalid_1's binary_logloss: 0.114658\n",
      "[9600]\ttraining's auc: 0.997059\ttraining's binary_logloss: 0.0615369\tvalid_1's auc: 0.973132\tvalid_1's binary_logloss: 0.114324\n",
      "[9800]\ttraining's auc: 0.997234\ttraining's binary_logloss: 0.0605472\tvalid_1's auc: 0.973181\tvalid_1's binary_logloss: 0.114132\n",
      "[10000]\ttraining's auc: 0.997401\ttraining's binary_logloss: 0.0595767\tvalid_1's auc: 0.973244\tvalid_1's binary_logloss: 0.113922\n",
      "[10200]\ttraining's auc: 0.997549\ttraining's binary_logloss: 0.0586437\tvalid_1's auc: 0.973297\tvalid_1's binary_logloss: 0.113733\n",
      "[10400]\ttraining's auc: 0.997691\ttraining's binary_logloss: 0.0577481\tvalid_1's auc: 0.973327\tvalid_1's binary_logloss: 0.113604\n",
      "[10600]\ttraining's auc: 0.997822\ttraining's binary_logloss: 0.0568332\tvalid_1's auc: 0.973437\tvalid_1's binary_logloss: 0.113296\n",
      "[10800]\ttraining's auc: 0.99795\ttraining's binary_logloss: 0.0559517\tvalid_1's auc: 0.973494\tvalid_1's binary_logloss: 0.113079\n",
      "[11000]\ttraining's auc: 0.998072\ttraining's binary_logloss: 0.0550824\tvalid_1's auc: 0.97354\tvalid_1's binary_logloss: 0.112935\n",
      "[11200]\ttraining's auc: 0.998193\ttraining's binary_logloss: 0.0542256\tvalid_1's auc: 0.973528\tvalid_1's binary_logloss: 0.112868\n",
      "[11400]\ttraining's auc: 0.9983\ttraining's binary_logloss: 0.0533904\tvalid_1's auc: 0.973552\tvalid_1's binary_logloss: 0.11275\n",
      "[11600]\ttraining's auc: 0.998399\ttraining's binary_logloss: 0.0525844\tvalid_1's auc: 0.973602\tvalid_1's binary_logloss: 0.11257\n",
      "[11800]\ttraining's auc: 0.998495\ttraining's binary_logloss: 0.0518178\tvalid_1's auc: 0.973602\tvalid_1's binary_logloss: 0.112519\n",
      "[12000]\ttraining's auc: 0.998595\ttraining's binary_logloss: 0.0510426\tvalid_1's auc: 0.97364\tvalid_1's binary_logloss: 0.112397\n",
      "[12200]\ttraining's auc: 0.998671\ttraining's binary_logloss: 0.0503278\tvalid_1's auc: 0.973683\tvalid_1's binary_logloss: 0.112272\n",
      "[12400]\ttraining's auc: 0.998747\ttraining's binary_logloss: 0.0496167\tvalid_1's auc: 0.973679\tvalid_1's binary_logloss: 0.112214\n",
      "[12600]\ttraining's auc: 0.99882\ttraining's binary_logloss: 0.0489252\tvalid_1's auc: 0.973701\tvalid_1's binary_logloss: 0.112114\n",
      "[12800]\ttraining's auc: 0.99889\ttraining's binary_logloss: 0.0481915\tvalid_1's auc: 0.973763\tvalid_1's binary_logloss: 0.111924\n",
      "[13000]\ttraining's auc: 0.998957\ttraining's binary_logloss: 0.0475318\tvalid_1's auc: 0.97379\tvalid_1's binary_logloss: 0.111816\n",
      "[13200]\ttraining's auc: 0.999019\ttraining's binary_logloss: 0.0468716\tvalid_1's auc: 0.973809\tvalid_1's binary_logloss: 0.111727\n",
      "[13400]\ttraining's auc: 0.999086\ttraining's binary_logloss: 0.046191\tvalid_1's auc: 0.973808\tvalid_1's binary_logloss: 0.111697\n",
      "[13600]\ttraining's auc: 0.999141\ttraining's binary_logloss: 0.0455459\tvalid_1's auc: 0.973823\tvalid_1's binary_logloss: 0.111633\n",
      "[13800]\ttraining's auc: 0.999192\ttraining's binary_logloss: 0.0449104\tvalid_1's auc: 0.973822\tvalid_1's binary_logloss: 0.111581\n",
      "[14000]\ttraining's auc: 0.999243\ttraining's binary_logloss: 0.0442994\tvalid_1's auc: 0.973814\tvalid_1's binary_logloss: 0.111538\n",
      "[14200]\ttraining's auc: 0.999284\ttraining's binary_logloss: 0.0437256\tvalid_1's auc: 0.973831\tvalid_1's binary_logloss: 0.111466\n",
      "[14400]\ttraining's auc: 0.999327\ttraining's binary_logloss: 0.0431387\tvalid_1's auc: 0.97386\tvalid_1's binary_logloss: 0.111353\n",
      "[14600]\ttraining's auc: 0.99937\ttraining's binary_logloss: 0.0425626\tvalid_1's auc: 0.973871\tvalid_1's binary_logloss: 0.111314\n",
      "[14800]\ttraining's auc: 0.999409\ttraining's binary_logloss: 0.0420008\tvalid_1's auc: 0.973851\tvalid_1's binary_logloss: 0.111309\n",
      "[15000]\ttraining's auc: 0.999449\ttraining's binary_logloss: 0.0414392\tvalid_1's auc: 0.973894\tvalid_1's binary_logloss: 0.1112\n",
      "[15200]\ttraining's auc: 0.999485\ttraining's binary_logloss: 0.0408841\tvalid_1's auc: 0.973898\tvalid_1's binary_logloss: 0.111183\n",
      "[15400]\ttraining's auc: 0.999518\ttraining's binary_logloss: 0.0403734\tvalid_1's auc: 0.973879\tvalid_1's binary_logloss: 0.111197\n",
      "Early stopping, best iteration is:\n",
      "[15045]\ttraining's auc: 0.999456\ttraining's binary_logloss: 0.0413139\tvalid_1's auc: 0.973909\tvalid_1's binary_logloss: 0.11116\n",
      "0:\ttest: 0.7151035\tbest: 0.7151035 (0)\ttotal: 976ms\tremaining: 1d 3h 7m 6s\n",
      "100:\ttest: 0.8604146\tbest: 0.8604146 (100)\ttotal: 1m 43s\tremaining: 1d 4h 31m 35s\n",
      "200:\ttest: 0.8821616\tbest: 0.8821616 (200)\ttotal: 3m 26s\tremaining: 1d 4h 29m 1s\n",
      "300:\ttest: 0.9029246\tbest: 0.9029246 (300)\ttotal: 5m 9s\tremaining: 1d 4h 26m 33s\n",
      "400:\ttest: 0.9149037\tbest: 0.9149037 (400)\ttotal: 6m 52s\tremaining: 1d 4h 25m 53s\n",
      "500:\ttest: 0.9243399\tbest: 0.9243399 (500)\ttotal: 8m 34s\tremaining: 1d 4h 24m 10s\n",
      "600:\ttest: 0.9316514\tbest: 0.9316514 (600)\ttotal: 10m 17s\tremaining: 1d 4h 21m 52s\n",
      "700:\ttest: 0.9373078\tbest: 0.9373078 (700)\ttotal: 12m\tremaining: 1d 4h 20m 58s\n",
      "800:\ttest: 0.9417260\tbest: 0.9417260 (800)\ttotal: 13m 43s\tremaining: 1d 4h 19m 18s\n",
      "900:\ttest: 0.9449032\tbest: 0.9449032 (900)\ttotal: 15m 26s\tremaining: 1d 4h 18m 7s\n",
      "1000:\ttest: 0.9475901\tbest: 0.9475901 (1000)\ttotal: 17m 9s\tremaining: 1d 4h 17m 11s\n",
      "1100:\ttest: 0.9494784\tbest: 0.9494784 (1100)\ttotal: 18m 52s\tremaining: 1d 4h 15m 7s\n",
      "1200:\ttest: 0.9515855\tbest: 0.9515855 (1200)\ttotal: 20m 34s\tremaining: 1d 4h 13m 5s\n",
      "1300:\ttest: 0.9535346\tbest: 0.9535346 (1300)\ttotal: 22m 17s\tremaining: 1d 4h 11m 22s\n",
      "1400:\ttest: 0.9552307\tbest: 0.9552307 (1400)\ttotal: 24m\tremaining: 1d 4h 10m 9s\n",
      "1500:\ttest: 0.9561974\tbest: 0.9561974 (1500)\ttotal: 25m 45s\tremaining: 1d 4h 10m 51s\n",
      "1600:\ttest: 0.9572924\tbest: 0.9572979 (1599)\ttotal: 27m 31s\tremaining: 1d 4h 11m 43s\n",
      "1700:\ttest: 0.9580126\tbest: 0.9580126 (1700)\ttotal: 29m 16s\tremaining: 1d 4h 11m 59s\n",
      "1800:\ttest: 0.9587103\tbest: 0.9587103 (1800)\ttotal: 31m\tremaining: 1d 4h 10m 59s\n",
      "1900:\ttest: 0.9592944\tbest: 0.9592944 (1900)\ttotal: 32m 45s\tremaining: 1d 4h 10m 5s\n",
      "2000:\ttest: 0.9597103\tbest: 0.9597103 (2000)\ttotal: 34m 32s\tremaining: 1d 4h 11m 26s\n",
      "2100:\ttest: 0.9602570\tbest: 0.9602570 (2100)\ttotal: 36m 28s\tremaining: 1d 4h 19m 46s\n",
      "2200:\ttest: 0.9604897\tbest: 0.9604900 (2197)\ttotal: 38m 15s\tremaining: 1d 4h 20m 19s\n",
      "2300:\ttest: 0.9605545\tbest: 0.9605635 (2273)\ttotal: 39m 58s\tremaining: 1d 4h 17m 20s\n",
      "2400:\ttest: 0.9607302\tbest: 0.9607330 (2387)\ttotal: 41m 41s\tremaining: 1d 4h 14m 28s\n",
      "2500:\ttest: 0.9608402\tbest: 0.9608415 (2497)\ttotal: 43m 23s\tremaining: 1d 4h 11m 48s\n",
      "2600:\ttest: 0.9609617\tbest: 0.9609617 (2600)\ttotal: 45m 6s\tremaining: 1d 4h 9m 3s\n",
      "2700:\ttest: 0.9612654\tbest: 0.9612654 (2700)\ttotal: 46m 48s\tremaining: 1d 4h 6m 27s\n",
      "2800:\ttest: 0.9614497\tbest: 0.9614513 (2798)\ttotal: 48m 31s\tremaining: 1d 4h 3m 57s\n",
      "2900:\ttest: 0.9614952\tbest: 0.9614979 (2894)\ttotal: 50m 13s\tremaining: 1d 4h 1m 13s\n",
      "3000:\ttest: 0.9615771\tbest: 0.9615793 (2980)\ttotal: 51m 56s\tremaining: 1d 3h 58m 37s\n",
      "3100:\ttest: 0.9616695\tbest: 0.9616695 (3100)\ttotal: 53m 38s\tremaining: 1d 3h 55m 59s\n",
      "3200:\ttest: 0.9617482\tbest: 0.9617483 (3195)\ttotal: 55m 20s\tremaining: 1d 3h 53m 36s\n",
      "3300:\ttest: 0.9618642\tbest: 0.9618677 (3297)\ttotal: 57m 2s\tremaining: 1d 3h 51m 9s\n",
      "3400:\ttest: 0.9619589\tbest: 0.9619612 (3389)\ttotal: 58m 44s\tremaining: 1d 3h 48m 31s\n",
      "3500:\ttest: 0.9619912\tbest: 0.9619918 (3496)\ttotal: 1h 25s\tremaining: 1d 3h 45m 30s\n",
      "3600:\ttest: 0.9620619\tbest: 0.9620662 (3592)\ttotal: 1h 2m 6s\tremaining: 1d 3h 42m 45s\n",
      "3700:\ttest: 0.9621430\tbest: 0.9621433 (3697)\ttotal: 1h 3m 48s\tremaining: 1d 3h 40m 5s\n",
      "3800:\ttest: 0.9623085\tbest: 0.9623112 (3796)\ttotal: 1h 5m 30s\tremaining: 1d 3h 37m 48s\n",
      "3900:\ttest: 0.9624014\tbest: 0.9624023 (3898)\ttotal: 1h 7m 11s\tremaining: 1d 3h 35m 10s\n",
      "4000:\ttest: 0.9624826\tbest: 0.9624830 (3999)\ttotal: 1h 8m 52s\tremaining: 1d 3h 32m 33s\n",
      "4100:\ttest: 0.9625922\tbest: 0.9625927 (4099)\ttotal: 1h 10m 33s\tremaining: 1d 3h 30m 3s\n",
      "4200:\ttest: 0.9626606\tbest: 0.9626621 (4198)\ttotal: 1h 12m 12s\tremaining: 1d 3h 26m 38s\n",
      "4300:\ttest: 0.9627740\tbest: 0.9627749 (4298)\ttotal: 1h 13m 53s\tremaining: 1d 3h 24m 14s\n",
      "4400:\ttest: 0.9628184\tbest: 0.9628184 (4400)\ttotal: 1h 15m 35s\tremaining: 1d 3h 21m 53s\n",
      "4500:\ttest: 0.9628459\tbest: 0.9628468 (4476)\ttotal: 1h 17m 16s\tremaining: 1d 3h 19m 29s\n",
      "4600:\ttest: 0.9628867\tbest: 0.9628874 (4597)\ttotal: 1h 19m 18s\tremaining: 1d 3h 24m 22s\n",
      "4700:\ttest: 0.9629745\tbest: 0.9629747 (4683)\ttotal: 1h 21m 5s\tremaining: 1d 3h 24m 3s\n",
      "4800:\ttest: 0.9630180\tbest: 0.9630182 (4799)\ttotal: 1h 22m 54s\tremaining: 1d 3h 23m 50s\n",
      "4900:\ttest: 0.9630411\tbest: 0.9630427 (4888)\ttotal: 1h 24m 40s\tremaining: 1d 3h 23m 4s\n",
      "5000:\ttest: 0.9630778\tbest: 0.9630783 (4999)\ttotal: 1h 26m 27s\tremaining: 1d 3h 22m 29s\n",
      "5100:\ttest: 0.9630994\tbest: 0.9631016 (5080)\ttotal: 1h 28m 14s\tremaining: 1d 3h 21m 31s\n",
      "5200:\ttest: 0.9631171\tbest: 0.9631184 (5184)\ttotal: 1h 29m 57s\tremaining: 1d 3h 19m 33s\n",
      "5300:\ttest: 0.9631577\tbest: 0.9631585 (5298)\ttotal: 1h 31m 41s\tremaining: 1d 3h 18m 3s\n",
      "5400:\ttest: 0.9631942\tbest: 0.9631946 (5398)\ttotal: 1h 33m 29s\tremaining: 1d 3h 17m 24s\n",
      "5500:\ttest: 0.9632206\tbest: 0.9632206 (5498)\ttotal: 1h 35m 14s\tremaining: 1d 3h 16m 12s\n",
      "5600:\ttest: 0.9632465\tbest: 0.9632467 (5598)\ttotal: 1h 37m 3s\tremaining: 1d 3h 15m 48s\n",
      "5700:\ttest: 0.9632854\tbest: 0.9632870 (5684)\ttotal: 1h 38m 50s\tremaining: 1d 3h 14m 51s\n",
      "5800:\ttest: 0.9633034\tbest: 0.9633034 (5800)\ttotal: 1h 40m 39s\tremaining: 1d 3h 14m 25s\n",
      "5900:\ttest: 0.9633404\tbest: 0.9633406 (5893)\ttotal: 1h 42m 25s\tremaining: 1d 3h 13m 16s\n",
      "6000:\ttest: 0.9633562\tbest: 0.9633564 (5957)\ttotal: 1h 44m 11s\tremaining: 1d 3h 12m 9s\n",
      "6100:\ttest: 0.9633638\tbest: 0.9633655 (6063)\ttotal: 1h 45m 58s\tremaining: 1d 3h 10m 58s\n",
      "6200:\ttest: 0.9633713\tbest: 0.9633739 (6174)\ttotal: 1h 47m 41s\tremaining: 1d 3h 9m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9633739116\n",
      "bestIteration = 6174\n",
      "\n",
      "Shrink model to first 6175 iterations.\n",
      "[18:53:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.67266\ttrain-auc:0.71632\tvalid-logloss:0.67271\tvalid-auc:0.70952\n",
      "[100]\ttrain-logloss:0.22608\ttrain-auc:0.91577\tvalid-logloss:0.22901\tvalid-auc:0.91329\n",
      "[200]\ttrain-logloss:0.18212\ttrain-auc:0.94394\tvalid-logloss:0.18665\tvalid-auc:0.93931\n",
      "[300]\ttrain-logloss:0.16501\ttrain-auc:0.95400\tvalid-logloss:0.17115\tvalid-auc:0.94760\n",
      "[400]\ttrain-logloss:0.15319\ttrain-auc:0.96034\tvalid-logloss:0.16097\tvalid-auc:0.95286\n",
      "[500]\ttrain-logloss:0.14543\ttrain-auc:0.96427\tvalid-logloss:0.15468\tvalid-auc:0.95595\n",
      "[600]\ttrain-logloss:0.13892\ttrain-auc:0.96744\tvalid-logloss:0.14969\tvalid-auc:0.95822\n",
      "[700]\ttrain-logloss:0.13331\ttrain-auc:0.97013\tvalid-logloss:0.14560\tvalid-auc:0.96006\n",
      "[800]\ttrain-logloss:0.12856\ttrain-auc:0.97234\tvalid-logloss:0.14253\tvalid-auc:0.96138\n",
      "[900]\ttrain-logloss:0.12406\ttrain-auc:0.97446\tvalid-logloss:0.13959\tvalid-auc:0.96270\n",
      "[1000]\ttrain-logloss:0.11998\ttrain-auc:0.97633\tvalid-logloss:0.13710\tvalid-auc:0.96375\n",
      "[1100]\ttrain-logloss:0.11633\ttrain-auc:0.97797\tvalid-logloss:0.13498\tvalid-auc:0.96466\n",
      "[1200]\ttrain-logloss:0.11311\ttrain-auc:0.97950\tvalid-logloss:0.13359\tvalid-auc:0.96519\n",
      "[1300]\ttrain-logloss:0.11017\ttrain-auc:0.98083\tvalid-logloss:0.13216\tvalid-auc:0.96585\n",
      "[1400]\ttrain-logloss:0.10715\ttrain-auc:0.98224\tvalid-logloss:0.13092\tvalid-auc:0.96639\n",
      "[1500]\ttrain-logloss:0.10416\ttrain-auc:0.98350\tvalid-logloss:0.12958\tvalid-auc:0.96694\n",
      "[1600]\ttrain-logloss:0.10139\ttrain-auc:0.98467\tvalid-logloss:0.12858\tvalid-auc:0.96731\n",
      "[1700]\ttrain-logloss:0.09872\ttrain-auc:0.98578\tvalid-logloss:0.12751\tvalid-auc:0.96778\n",
      "[1800]\ttrain-logloss:0.09625\ttrain-auc:0.98672\tvalid-logloss:0.12658\tvalid-auc:0.96808\n",
      "[1900]\ttrain-logloss:0.09370\ttrain-auc:0.98767\tvalid-logloss:0.12565\tvalid-auc:0.96845\n",
      "[2000]\ttrain-logloss:0.09133\ttrain-auc:0.98858\tvalid-logloss:0.12485\tvalid-auc:0.96880\n",
      "[2100]\ttrain-logloss:0.08914\ttrain-auc:0.98938\tvalid-logloss:0.12412\tvalid-auc:0.96911\n",
      "[2200]\ttrain-logloss:0.08703\ttrain-auc:0.99011\tvalid-logloss:0.12348\tvalid-auc:0.96936\n",
      "[2300]\ttrain-logloss:0.08510\ttrain-auc:0.99074\tvalid-logloss:0.12292\tvalid-auc:0.96951\n",
      "[2400]\ttrain-logloss:0.08302\ttrain-auc:0.99140\tvalid-logloss:0.12225\tvalid-auc:0.96976\n",
      "[2500]\ttrain-logloss:0.08109\ttrain-auc:0.99200\tvalid-logloss:0.12161\tvalid-auc:0.97000\n",
      "[2600]\ttrain-logloss:0.07933\ttrain-auc:0.99253\tvalid-logloss:0.12117\tvalid-auc:0.97011\n",
      "[2700]\ttrain-logloss:0.07753\ttrain-auc:0.99304\tvalid-logloss:0.12056\tvalid-auc:0.97034\n",
      "[2800]\ttrain-logloss:0.07584\ttrain-auc:0.99352\tvalid-logloss:0.12013\tvalid-auc:0.97048\n",
      "[2900]\ttrain-logloss:0.07421\ttrain-auc:0.99394\tvalid-logloss:0.11972\tvalid-auc:0.97064\n",
      "[3000]\ttrain-logloss:0.07245\ttrain-auc:0.99438\tvalid-logloss:0.11913\tvalid-auc:0.97084\n",
      "[3100]\ttrain-logloss:0.07093\ttrain-auc:0.99477\tvalid-logloss:0.11890\tvalid-auc:0.97091\n",
      "[3200]\ttrain-logloss:0.06944\ttrain-auc:0.99513\tvalid-logloss:0.11865\tvalid-auc:0.97096\n",
      "[3300]\ttrain-logloss:0.06797\ttrain-auc:0.99548\tvalid-logloss:0.11832\tvalid-auc:0.97109\n",
      "[3400]\ttrain-logloss:0.06658\ttrain-auc:0.99579\tvalid-logloss:0.11795\tvalid-auc:0.97121\n",
      "[3500]\ttrain-logloss:0.06521\ttrain-auc:0.99609\tvalid-logloss:0.11764\tvalid-auc:0.97135\n",
      "[3600]\ttrain-logloss:0.06387\ttrain-auc:0.99635\tvalid-logloss:0.11729\tvalid-auc:0.97148\n",
      "[3700]\ttrain-logloss:0.06265\ttrain-auc:0.99659\tvalid-logloss:0.11707\tvalid-auc:0.97154\n",
      "[3800]\ttrain-logloss:0.06139\ttrain-auc:0.99682\tvalid-logloss:0.11678\tvalid-auc:0.97165\n",
      "[3900]\ttrain-logloss:0.06019\ttrain-auc:0.99705\tvalid-logloss:0.11655\tvalid-auc:0.97174\n",
      "[4000]\ttrain-logloss:0.05904\ttrain-auc:0.99723\tvalid-logloss:0.11637\tvalid-auc:0.97175\n",
      "[4100]\ttrain-logloss:0.05782\ttrain-auc:0.99744\tvalid-logloss:0.11613\tvalid-auc:0.97185\n",
      "[4200]\ttrain-logloss:0.05673\ttrain-auc:0.99762\tvalid-logloss:0.11600\tvalid-auc:0.97190\n",
      "[4300]\ttrain-logloss:0.05567\ttrain-auc:0.99779\tvalid-logloss:0.11591\tvalid-auc:0.97192\n",
      "[4400]\ttrain-logloss:0.05462\ttrain-auc:0.99794\tvalid-logloss:0.11572\tvalid-auc:0.97197\n",
      "[4500]\ttrain-logloss:0.05356\ttrain-auc:0.99810\tvalid-logloss:0.11552\tvalid-auc:0.97203\n",
      "[4600]\ttrain-logloss:0.05260\ttrain-auc:0.99822\tvalid-logloss:0.11545\tvalid-auc:0.97202\n",
      "[4616]\ttrain-logloss:0.05244\ttrain-auc:0.99825\tvalid-logloss:0.11541\tvalid-auc:0.97204\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "oof_lgb = np.zeros([len(x_train),])\n",
    "oof_xgb = np.zeros([len(x_train),])\n",
    "oof_ctb = np.zeros([len(x_train),])\n",
    "predictions_lgb = np.zeros([len(x_test),])\n",
    "predictions_xgb = np.zeros([len(x_test),])\n",
    "predictions_ctb = np.zeros([len(x_test),])\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    lgb_trn_data = lgb.Dataset(x_train.iloc[trn_idx], y_train.iloc[trn_idx])\n",
    "    lgb_val_data = lgb.Dataset(x_train.iloc[val_idx], y_train.iloc[val_idx])\n",
    "    \n",
    "    cat_trn_data = ctb.Pool(data=x_train.iloc[trn_idx],label=y_train.iloc[trn_idx])\n",
    "    cat_val_data = ctb.Pool(data=x_train.iloc[val_idx],label=y_train.iloc[val_idx])\n",
    "    \n",
    "    xgb_trn_data = xgb.DMatrix(x_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n",
    "    xgb_val_data = xgb.DMatrix(x_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    " \n",
    "    num_round = 100000\n",
    "    clf_lgb = lgb.train(params_lgb,\n",
    "                        lgb_trn_data,\n",
    "                        num_round,\n",
    "                        valid_sets = [lgb_trn_data, lgb_val_data], \n",
    "                        verbose_eval = 200,\n",
    "                        early_stopping_rounds = 500)\n",
    "    clf_lgb.save_model(filename=f'./saved_model/{fold_+1}_fold_lgb.txt',num_iteration=clf_lgb.best_iteration)\n",
    "    \n",
    "    clf_ctb = ctb.CatBoostClassifier(iterations = 100000,early_stopping_rounds = 100, **params_ctb)\n",
    "    clf_ctb.fit(cat_trn_data, eval_set=cat_val_data,verbose_eval=100)\n",
    "    clf_ctb.save_model(f'./saved_model/{fold_+1}_fold_ctb.txt')\n",
    "    \n",
    "    watchlist = [(xgb_trn_data, 'train'), (xgb_val_data, 'valid')]\n",
    "    clf_xgb = xgb.train(params_xgb, xgb_trn_data, num_round, watchlist, verbose_eval=100, early_stopping_rounds=100)\n",
    "    clf_xgb.save_model(f'./saved_model/{fold_+1}_fold_xgb.txt')\n",
    "    \n",
    "    oof_lgb[val_idx] = clf_lgb.predict(x_train.iloc[val_idx], num_iteration=clf_lgb.best_iteration)\n",
    "    oof_ctb[val_idx] = clf_ctb.predict(x_train.iloc[val_idx])\n",
    "    oof_xgb[val_idx] = clf_xgb.predict(xgb.DMatrix(x_train.iloc[val_idx]))\n",
    "    \n",
    "    predictions_lgb += clf_lgb.predict(x_test, num_iteration=clf_lgb.best_iteration) / folds.n_splits\n",
    "    predictions_ctb += clf_ctb.predict(x_test) / folds.n_splits\n",
    "    predictions_xgb += clf_xgb.predict(xgb.DMatrix(x_test)) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc:0.7943847782260391\n",
      "acc:0.9498926826513033\n",
      "F1 score: 0.7044271375619509\n",
      "Precision score: 0.8523483168715985\n",
      "Recall score: 0.6002555184896018\n",
      "(F1+auc)/2: 0.749405957893995\n"
     ]
    }
   ],
   "source": [
    "y_valid = y_train\n",
    "y_pre = [int(x>0.2) for x in oof_ctb]\n",
    "acc = [int(i==j) for i,j in zip(y_valid, y_pre)]\n",
    "acc = sum(acc)/len(acc)\n",
    "f1 = f1_score(y_valid, y_pre,average='binary')\n",
    "precision = precision_score(y_valid, y_pre,average='binary')\n",
    "recall = recall_score(y_valid, y_pre,average='binary')\n",
    "roc_auc = roc_auc_score(y_valid, oof_ctb)\n",
    "score = (f1+roc_auc)/2\n",
    "print(f\"roc_auc:{roc_auc}\")\n",
    "print(f\"acc:{acc}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"Precision score: {precision}\")\n",
    "print(f\"Recall score: {recall}\")\n",
    "print(f\"(F1+auc)/2: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob = pd.DataFrame()\n",
    "train_prob['lgb'] = oof_lgb\n",
    "train_prob['xgb'] = oof_xgb\n",
    "train_prob['ctb'] = oof_ctb\n",
    "train_prob['label'] = y_train\n",
    "\n",
    "test_prob = pd.DataFrame()\n",
    "test_prob['lgb'] = predictions_lgb\n",
    "test_prob['xgb'] = predictions_xgb\n",
    "test_prob['ctb'] = predictions_ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lrg = LinearRegression()\n",
    "\n",
    "lrg.fit(train_prob[['lgb','xgb','ctb']], train_prob.label)\n",
    "prob_y = lrg.predict(test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(x):\n",
    "    if x[0] == 1:\n",
    "        return 0.5 + 0.1 * x[1]\n",
    "    else:\n",
    "        return 0.4 + 0.1 * x[1]\n",
    "    \n",
    "test_sub['related_p'] = prob_y\n",
    "test_sub['rank'] = 1\n",
    "test_sub['rank'] = test_sub.groupby('rank')['related_p'].rank(method='first', ascending=False)\n",
    "test_sub['related_f1'] = 0\n",
    "\n",
    "# 阈值换分，根据提交全1测试大概4570-4590之间\n",
    "test_sub.loc[test_sub['rank'] < int(4584), 'related_f1'] = 1\n",
    "\n",
    "test_sub['related_prob'] = test_sub[['related_f1', 'related_p']].apply(lambda x: get_prob(x), axis=1)\n",
    "test_sub[['food_id', 'disease_id', 'related_prob']].to_csv('./results/submit_xgb_lgb_ctbv2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('hahally')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b392b8fd03aaa23b81d80cb958fa34e0858ce7005853273b3f87304f34e74ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
